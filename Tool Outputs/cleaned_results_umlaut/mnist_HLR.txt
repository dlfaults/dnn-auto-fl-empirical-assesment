D:\nargiz\github\umlaut\venvUMLT\Scripts\python.exe D:/nargiz/github/umlaut/mnist_lr_0.001.py
Using TensorFlow backend.
2023-03-22 01:24:08.161653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2023-03-22 01:24:09.793840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2023-03-22 01:24:09.819383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0b:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-22 01:24:09.819567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2023-03-22 01:24:09.825079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2023-03-22 01:24:09.827830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2023-03-22 01:24:09.828838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2023-03-22 01:24:09.832108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2023-03-22 01:24:09.834406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2023-03-22 01:24:09.840801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2023-03-22 01:24:09.840909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2023-03-22 01:24:09.841211: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2023-03-22 01:24:09.841995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0b:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-22 01:24:09.842165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2023-03-22 01:24:09.842237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2023-03-22 01:24:09.842307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2023-03-22 01:24:09.842376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2023-03-22 01:24:09.842448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2023-03-22 01:24:09.842523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2023-03-22 01:24:09.842612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2023-03-22 01:24:09.842693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2023-03-22 01:24:10.280500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-22 01:24:10.280589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2023-03-22 01:24:10.280636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2023-03-22 01:24:10.280784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6704 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:0b:00.0, compute capability: 7.5)
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
2023-03-22 01:24:11.324048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2023-03-22 01:24:11.499420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2023-03-22 01:24:12.220273: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.
 - 4s - loss: 2.2934 - accuracy: 0.1301 - val_loss: 2.2583 - val_accuracy: 0.2289
Epoch 2/12
 - 3s - loss: 2.2382 - accuracy: 0.2286 - val_loss: 2.1919 - val_accuracy: 0.5138
Epoch 3/12
 - 3s - loss: 2.1672 - accuracy: 0.3492 - val_loss: 2.0986 - val_accuracy: 0.6822
Epoch 4/12
 - 3s - loss: 2.0671 - accuracy: 0.4469 - val_loss: 1.9672 - val_accuracy: 0.7362

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.9298 - accuracy: 0.5215 - val_loss: 1.7934 - val_accuracy: 0.7524

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.7613 - accuracy: 0.5695 - val_loss: 1.5846 - val_accuracy: 0.7648

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5774 - accuracy: 0.6009 - val_loss: 1.3680 - val_accuracy: 0.7794

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.4068 - accuracy: 0.6309 - val_loss: 1.1747 - val_accuracy: 0.7933

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2600 - accuracy: 0.6547 - val_loss: 1.0167 - val_accuracy: 0.8077

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1430 - accuracy: 0.6744 - val_loss: 0.8941 - val_accuracy: 0.8204

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0541 - accuracy: 0.6937 - val_loss: 0.8012 - val_accuracy: 0.8313

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9761 - accuracy: 0.7104 - val_loss: 0.7292 - val_accuracy: 0.8391

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7292379285812378
Test accuracy: 0.8391000032424927
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2725 - accuracy: 0.1573 - val_loss: 2.2294 - val_accuracy: 0.3278
Epoch 2/12
 - 3s - loss: 2.2027 - accuracy: 0.2734 - val_loss: 2.1406 - val_accuracy: 0.5238
Epoch 3/12
 - 3s - loss: 2.1115 - accuracy: 0.3731 - val_loss: 2.0244 - val_accuracy: 0.6235
Epoch 4/12
 - 3s - loss: 1.9911 - accuracy: 0.4530 - val_loss: 1.8749 - val_accuracy: 0.6749

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8471 - accuracy: 0.5159 - val_loss: 1.6946 - val_accuracy: 0.7148

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.6804 - accuracy: 0.5674 - val_loss: 1.4945 - val_accuracy: 0.7569

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5101 - accuracy: 0.6058 - val_loss: 1.2958 - val_accuracy: 0.7878

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.3575 - accuracy: 0.6349 - val_loss: 1.1190 - val_accuracy: 0.8083

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2232 - accuracy: 0.6607 - val_loss: 0.9728 - val_accuracy: 0.8236

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1089 - accuracy: 0.6863 - val_loss: 0.8567 - val_accuracy: 0.8363

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0272 - accuracy: 0.7025 - val_loss: 0.7674 - val_accuracy: 0.8430

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9509 - accuracy: 0.7221 - val_loss: 0.6974 - val_accuracy: 0.8504

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.697427155971527
Test accuracy: 0.8503999710083008
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2892 - accuracy: 0.1216 - val_loss: 2.2484 - val_accuracy: 0.2415
Epoch 2/12
 - 3s - loss: 2.2261 - accuracy: 0.2328 - val_loss: 2.1745 - val_accuracy: 0.4609
Epoch 3/12
 - 3s - loss: 2.1489 - accuracy: 0.3435 - val_loss: 2.0724 - val_accuracy: 0.6293
Epoch 4/12
 - 3s - loss: 2.0410 - accuracy: 0.4387 - val_loss: 1.9305 - val_accuracy: 0.7104

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8951 - accuracy: 0.5153 - val_loss: 1.7465 - val_accuracy: 0.7514

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.7243 - accuracy: 0.5640 - val_loss: 1.5347 - val_accuracy: 0.7718

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5432 - accuracy: 0.6028 - val_loss: 1.3222 - val_accuracy: 0.7865

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.3769 - accuracy: 0.6324 - val_loss: 1.1349 - val_accuracy: 0.7970

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2310 - accuracy: 0.6618 - val_loss: 0.9830 - val_accuracy: 0.8105

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1172 - accuracy: 0.6837 - val_loss: 0.8661 - val_accuracy: 0.8225

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0308 - accuracy: 0.6987 - val_loss: 0.7782 - val_accuracy: 0.8320

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9579 - accuracy: 0.7147 - val_loss: 0.7088 - val_accuracy: 0.8419

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7087946211814881
Test accuracy: 0.8418999910354614
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2909 - accuracy: 0.1583 - val_loss: 2.2739 - val_accuracy: 0.3851
Epoch 2/12
 - 3s - loss: 2.2623 - accuracy: 0.2719 - val_loss: 2.2387 - val_accuracy: 0.5193
Epoch 3/12
 - 3s - loss: 2.2250 - accuracy: 0.3667 - val_loss: 2.1911 - val_accuracy: 0.5749
Epoch 4/12
 - 3s - loss: 2.1728 - accuracy: 0.4339 - val_loss: 2.1248 - val_accuracy: 0.6164

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.1009 - accuracy: 0.4755 - val_loss: 2.0324 - val_accuracy: 0.6528

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 2.0027 - accuracy: 0.5114 - val_loss: 1.9051 - val_accuracy: 0.6871

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.8715 - accuracy: 0.5451 - val_loss: 1.7392 - val_accuracy: 0.7217

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.7102 - accuracy: 0.5770 - val_loss: 1.5417 - val_accuracy: 0.7512

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.5422 - accuracy: 0.6028 - val_loss: 1.3392 - val_accuracy: 0.7709

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.3765 - accuracy: 0.6326 - val_loss: 1.1551 - val_accuracy: 0.7880

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.2380 - accuracy: 0.6546 - val_loss: 1.0022 - val_accuracy: 0.8049

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.1281 - accuracy: 0.6779 - val_loss: 0.8831 - val_accuracy: 0.8191

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.8830893470764161
Test accuracy: 0.819100022315979
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2834 - accuracy: 0.1454 - val_loss: 2.2445 - val_accuracy: 0.3381
Epoch 2/12
 - 3s - loss: 2.2207 - accuracy: 0.2598 - val_loss: 2.1679 - val_accuracy: 0.4807
Epoch 3/12
 - 3s - loss: 2.1419 - accuracy: 0.3576 - val_loss: 2.0685 - val_accuracy: 0.5793
Epoch 4/12
 - 3s - loss: 2.0373 - accuracy: 0.4424 - val_loss: 1.9334 - val_accuracy: 0.6367

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8993 - accuracy: 0.5061 - val_loss: 1.7575 - val_accuracy: 0.6771

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.7337 - accuracy: 0.5582 - val_loss: 1.5554 - val_accuracy: 0.7164

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5565 - accuracy: 0.5921 - val_loss: 1.3493 - val_accuracy: 0.7510

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.3896 - accuracy: 0.6269 - val_loss: 1.1618 - val_accuracy: 0.7862

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2491 - accuracy: 0.6518 - val_loss: 1.0079 - val_accuracy: 0.8065

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1329 - accuracy: 0.6763 - val_loss: 0.8866 - val_accuracy: 0.8202

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0398 - accuracy: 0.6960 - val_loss: 0.7934 - val_accuracy: 0.8306

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9675 - accuracy: 0.7120 - val_loss: 0.7202 - val_accuracy: 0.8430

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7202131424903869
Test accuracy: 0.8429999947547913
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2906 - accuracy: 0.1183 - val_loss: 2.2652 - val_accuracy: 0.2496
Epoch 2/12
 - 3s - loss: 2.2507 - accuracy: 0.2155 - val_loss: 2.2177 - val_accuracy: 0.4828
Epoch 3/12
 - 3s - loss: 2.2019 - accuracy: 0.3087 - val_loss: 2.1551 - val_accuracy: 0.5741
Epoch 4/12
 - 3s - loss: 2.1359 - accuracy: 0.3867 - val_loss: 2.0665 - val_accuracy: 0.6480

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0405 - accuracy: 0.4563 - val_loss: 1.9411 - val_accuracy: 0.7040

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.9101 - accuracy: 0.5152 - val_loss: 1.7747 - val_accuracy: 0.7593

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.7531 - accuracy: 0.5635 - val_loss: 1.5737 - val_accuracy: 0.7869

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.5743 - accuracy: 0.6085 - val_loss: 1.3593 - val_accuracy: 0.8044

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.3987 - accuracy: 0.6371 - val_loss: 1.1616 - val_accuracy: 0.8163

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2500 - accuracy: 0.6647 - val_loss: 0.9988 - val_accuracy: 0.8282

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.1284 - accuracy: 0.6878 - val_loss: 0.8730 - val_accuracy: 0.8369

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0368 - accuracy: 0.7031 - val_loss: 0.7794 - val_accuracy: 0.8440

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7793775681495666
Test accuracy: 0.843999981880188
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2916 - accuracy: 0.1482 - val_loss: 2.2704 - val_accuracy: 0.3498
Epoch 2/12
 - 3s - loss: 2.2556 - accuracy: 0.2519 - val_loss: 2.2261 - val_accuracy: 0.5364
Epoch 3/12
 - 3s - loss: 2.2081 - accuracy: 0.3495 - val_loss: 2.1646 - val_accuracy: 0.6179
Epoch 4/12
 - 3s - loss: 2.1423 - accuracy: 0.4298 - val_loss: 2.0778 - val_accuracy: 0.6589

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0489 - accuracy: 0.4900 - val_loss: 1.9555 - val_accuracy: 0.6900

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.9183 - accuracy: 0.5452 - val_loss: 1.7872 - val_accuracy: 0.7187

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.7551 - accuracy: 0.5825 - val_loss: 1.5771 - val_accuracy: 0.7454

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.5662 - accuracy: 0.6168 - val_loss: 1.3498 - val_accuracy: 0.7750

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.3846 - accuracy: 0.6400 - val_loss: 1.1430 - val_accuracy: 0.7977

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2353 - accuracy: 0.6654 - val_loss: 0.9784 - val_accuracy: 0.8142

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.1100 - accuracy: 0.6845 - val_loss: 0.8536 - val_accuracy: 0.8273

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0205 - accuracy: 0.7026 - val_loss: 0.7626 - val_accuracy: 0.8357

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7626489914894105
Test accuracy: 0.8356999754905701
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2752 - accuracy: 0.1612 - val_loss: 2.2336 - val_accuracy: 0.3418
Epoch 2/12
 - 3s - loss: 2.2101 - accuracy: 0.2675 - val_loss: 2.1562 - val_accuracy: 0.4403
Epoch 3/12
 - 3s - loss: 2.1303 - accuracy: 0.3559 - val_loss: 2.0564 - val_accuracy: 0.5231
Epoch 4/12
 - 3s - loss: 2.0265 - accuracy: 0.4353 - val_loss: 1.9248 - val_accuracy: 0.6165

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8950 - accuracy: 0.5001 - val_loss: 1.7624 - val_accuracy: 0.6821

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.7427 - accuracy: 0.5478 - val_loss: 1.5766 - val_accuracy: 0.7308

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5770 - accuracy: 0.5934 - val_loss: 1.3799 - val_accuracy: 0.7616

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.4174 - accuracy: 0.6256 - val_loss: 1.1962 - val_accuracy: 0.7847

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2815 - accuracy: 0.6497 - val_loss: 1.0410 - val_accuracy: 0.8027

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1614 - accuracy: 0.6726 - val_loss: 0.9154 - val_accuracy: 0.8149

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 4s - loss: 1.0671 - accuracy: 0.6932 - val_loss: 0.8172 - val_accuracy: 0.8257

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9906 - accuracy: 0.7103 - val_loss: 0.7406 - val_accuracy: 0.8351

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7406286288261413
Test accuracy: 0.835099995136261
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2869 - accuracy: 0.1374 - val_loss: 2.2671 - val_accuracy: 0.2001
Epoch 2/12
 - 3s - loss: 2.2577 - accuracy: 0.2103 - val_loss: 2.2312 - val_accuracy: 0.3951
Epoch 3/12
 - 3s - loss: 2.2192 - accuracy: 0.2968 - val_loss: 2.1833 - val_accuracy: 0.5383
Epoch 4/12
 - 3s - loss: 2.1674 - accuracy: 0.3740 - val_loss: 2.1180 - val_accuracy: 0.6069

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0967 - accuracy: 0.4394 - val_loss: 2.0275 - val_accuracy: 0.6584

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.9995 - accuracy: 0.4984 - val_loss: 1.9022 - val_accuracy: 0.7090

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.8686 - accuracy: 0.5455 - val_loss: 1.7343 - val_accuracy: 0.7560

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.7067 - accuracy: 0.5837 - val_loss: 1.5300 - val_accuracy: 0.7852

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.5297 - accuracy: 0.6176 - val_loss: 1.3138 - val_accuracy: 0.8074

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.3542 - accuracy: 0.6478 - val_loss: 1.1153 - val_accuracy: 0.8212

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.2071 - accuracy: 0.6730 - val_loss: 0.9551 - val_accuracy: 0.8323

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0941 - accuracy: 0.6891 - val_loss: 0.8362 - val_accuracy: 0.8421

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.8361972030639648
Test accuracy: 0.8421000242233276
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2754 - accuracy: 0.1730 - val_loss: 2.2323 - val_accuracy: 0.4081
Epoch 2/12
 - 3s - loss: 2.2051 - accuracy: 0.3032 - val_loss: 2.1477 - val_accuracy: 0.5137
Epoch 3/12
 - 3s - loss: 2.1178 - accuracy: 0.4032 - val_loss: 2.0366 - val_accuracy: 0.5856
Epoch 4/12
 - 3s - loss: 2.0016 - accuracy: 0.4753 - val_loss: 1.8877 - val_accuracy: 0.6416

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8495 - accuracy: 0.5301 - val_loss: 1.6982 - val_accuracy: 0.6878

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.6710 - accuracy: 0.5707 - val_loss: 1.4861 - val_accuracy: 0.7285

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.4938 - accuracy: 0.6045 - val_loss: 1.2805 - val_accuracy: 0.7594

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.3330 - accuracy: 0.6325 - val_loss: 1.1024 - val_accuracy: 0.7835

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2016 - accuracy: 0.6574 - val_loss: 0.9617 - val_accuracy: 0.7995

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.0997 - accuracy: 0.6776 - val_loss: 0.8543 - val_accuracy: 0.8145

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0118 - accuracy: 0.6976 - val_loss: 0.7711 - val_accuracy: 0.8262

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9440 - accuracy: 0.7153 - val_loss: 0.7057 - val_accuracy: 0.8346

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7056766492843628
Test accuracy: 0.8345999717712402
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2929 - accuracy: 0.1295 - val_loss: 2.2748 - val_accuracy: 0.2490
Epoch 2/12
 - 3s - loss: 2.2625 - accuracy: 0.2023 - val_loss: 2.2377 - val_accuracy: 0.3948
Epoch 3/12
 - 3s - loss: 2.2226 - accuracy: 0.2843 - val_loss: 2.1865 - val_accuracy: 0.5100
Epoch 4/12
 - 3s - loss: 2.1668 - accuracy: 0.3635 - val_loss: 2.1141 - val_accuracy: 0.5918

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0894 - accuracy: 0.4272 - val_loss: 2.0141 - val_accuracy: 0.6526

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.9819 - accuracy: 0.4892 - val_loss: 1.8790 - val_accuracy: 0.7136

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.8447 - accuracy: 0.5444 - val_loss: 1.7051 - val_accuracy: 0.7545

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.6798 - accuracy: 0.5897 - val_loss: 1.5015 - val_accuracy: 0.7791

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.5034 - accuracy: 0.6201 - val_loss: 1.2927 - val_accuracy: 0.7936

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.3433 - accuracy: 0.6414 - val_loss: 1.1087 - val_accuracy: 0.8042

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.2103 - accuracy: 0.6641 - val_loss: 0.9641 - val_accuracy: 0.8153

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.1001 - accuracy: 0.6861 - val_loss: 0.8544 - val_accuracy: 0.8215

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.8543692001342773
Test accuracy: 0.8215000033378601
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2846 - accuracy: 0.1402 - val_loss: 2.2536 - val_accuracy: 0.2256
Epoch 2/12
 - 3s - loss: 2.2337 - accuracy: 0.2489 - val_loss: 2.1923 - val_accuracy: 0.4678
Epoch 3/12
 - 3s - loss: 2.1694 - accuracy: 0.3530 - val_loss: 2.1114 - val_accuracy: 0.5607
Epoch 4/12
 - 3s - loss: 2.0830 - accuracy: 0.4349 - val_loss: 1.9998 - val_accuracy: 0.6355

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.9666 - accuracy: 0.4931 - val_loss: 1.8504 - val_accuracy: 0.6926

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.8211 - accuracy: 0.5403 - val_loss: 1.6666 - val_accuracy: 0.7264

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.6522 - accuracy: 0.5755 - val_loss: 1.4645 - val_accuracy: 0.7515

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.4851 - accuracy: 0.6059 - val_loss: 1.2694 - val_accuracy: 0.7772

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.3358 - accuracy: 0.6334 - val_loss: 1.1011 - val_accuracy: 0.7944

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2119 - accuracy: 0.6558 - val_loss: 0.9666 - val_accuracy: 0.8097

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.1088 - accuracy: 0.6786 - val_loss: 0.8612 - val_accuracy: 0.8204

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0302 - accuracy: 0.6937 - val_loss: 0.7799 - val_accuracy: 0.8308

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.779919552230835
Test accuracy: 0.8307999968528748
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2773 - accuracy: 0.1753 - val_loss: 2.2484 - val_accuracy: 0.3381
Epoch 2/12
 - 3s - loss: 2.2305 - accuracy: 0.2748 - val_loss: 2.1886 - val_accuracy: 0.5097
Epoch 3/12
 - 3s - loss: 2.1673 - accuracy: 0.3751 - val_loss: 2.1086 - val_accuracy: 0.5837
Epoch 4/12
 - 3s - loss: 2.0828 - accuracy: 0.4523 - val_loss: 2.0002 - val_accuracy: 0.6474

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.9698 - accuracy: 0.5132 - val_loss: 1.8557 - val_accuracy: 0.6922

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.8262 - accuracy: 0.5570 - val_loss: 1.6745 - val_accuracy: 0.7289

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.6560 - accuracy: 0.5924 - val_loss: 1.4674 - val_accuracy: 0.7577

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.4803 - accuracy: 0.6210 - val_loss: 1.2622 - val_accuracy: 0.7797

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.3220 - accuracy: 0.6455 - val_loss: 1.0859 - val_accuracy: 0.7957

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1881 - accuracy: 0.6709 - val_loss: 0.9464 - val_accuracy: 0.8114

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0866 - accuracy: 0.6902 - val_loss: 0.8403 - val_accuracy: 0.8219

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0070 - accuracy: 0.7056 - val_loss: 0.7590 - val_accuracy: 0.8330

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7590400248527527
Test accuracy: 0.8330000042915344
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2764 - accuracy: 0.1532 - val_loss: 2.2381 - val_accuracy: 0.3725
Epoch 2/12
 - 3s - loss: 2.2137 - accuracy: 0.2700 - val_loss: 2.1591 - val_accuracy: 0.5444
Epoch 3/12
 - 3s - loss: 2.1315 - accuracy: 0.3782 - val_loss: 2.0571 - val_accuracy: 0.6106
Epoch 4/12
 - 3s - loss: 2.0277 - accuracy: 0.4546 - val_loss: 1.9266 - val_accuracy: 0.6502

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8956 - accuracy: 0.5064 - val_loss: 1.7614 - val_accuracy: 0.6893

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.7372 - accuracy: 0.5526 - val_loss: 1.5696 - val_accuracy: 0.7298

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5704 - accuracy: 0.5880 - val_loss: 1.3711 - val_accuracy: 0.7649

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.4095 - accuracy: 0.6194 - val_loss: 1.1882 - val_accuracy: 0.7864

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2715 - accuracy: 0.6438 - val_loss: 1.0353 - val_accuracy: 0.8061

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1579 - accuracy: 0.6657 - val_loss: 0.9124 - val_accuracy: 0.8195

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0643 - accuracy: 0.6862 - val_loss: 0.8170 - val_accuracy: 0.8297

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9888 - accuracy: 0.7053 - val_loss: 0.7426 - val_accuracy: 0.8375

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.742608802318573
Test accuracy: 0.8374999761581421
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2989 - accuracy: 0.1061 - val_loss: 2.2764 - val_accuracy: 0.2039
Epoch 2/12
 - 3s - loss: 2.2611 - accuracy: 0.2043 - val_loss: 2.2305 - val_accuracy: 0.3447
Epoch 3/12
 - 3s - loss: 2.2121 - accuracy: 0.3034 - val_loss: 2.1685 - val_accuracy: 0.4581
Epoch 4/12
 - 3s - loss: 2.1448 - accuracy: 0.3848 - val_loss: 2.0837 - val_accuracy: 0.5464

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0538 - accuracy: 0.4519 - val_loss: 1.9664 - val_accuracy: 0.6077

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.9302 - accuracy: 0.4991 - val_loss: 1.8074 - val_accuracy: 0.6500

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.7767 - accuracy: 0.5393 - val_loss: 1.6116 - val_accuracy: 0.7035

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.6008 - accuracy: 0.5818 - val_loss: 1.3988 - val_accuracy: 0.7472

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.4273 - accuracy: 0.6132 - val_loss: 1.2013 - val_accuracy: 0.7735

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2787 - accuracy: 0.6404 - val_loss: 1.0371 - val_accuracy: 0.7933

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.1566 - accuracy: 0.6658 - val_loss: 0.9092 - val_accuracy: 0.8123

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0611 - accuracy: 0.6891 - val_loss: 0.8121 - val_accuracy: 0.8223

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.8120765754699707
Test accuracy: 0.8223000168800354
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2895 - accuracy: 0.1302 - val_loss: 2.2643 - val_accuracy: 0.2528
Epoch 2/12
 - 3s - loss: 2.2505 - accuracy: 0.2133 - val_loss: 2.2175 - val_accuracy: 0.4041
Epoch 3/12
 - 3s - loss: 2.2024 - accuracy: 0.2986 - val_loss: 2.1573 - val_accuracy: 0.4825
Epoch 4/12
 - 3s - loss: 2.1388 - accuracy: 0.3700 - val_loss: 2.0753 - val_accuracy: 0.5511

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0506 - accuracy: 0.4297 - val_loss: 1.9611 - val_accuracy: 0.6182

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.9313 - accuracy: 0.4905 - val_loss: 1.8077 - val_accuracy: 0.6834

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.7824 - accuracy: 0.5396 - val_loss: 1.6195 - val_accuracy: 0.7401

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.6127 - accuracy: 0.5849 - val_loss: 1.4130 - val_accuracy: 0.7772

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.4434 - accuracy: 0.6194 - val_loss: 1.2136 - val_accuracy: 0.8020

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2900 - accuracy: 0.6477 - val_loss: 1.0415 - val_accuracy: 0.8193

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.1658 - accuracy: 0.6707 - val_loss: 0.9064 - val_accuracy: 0.8310

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0669 - accuracy: 0.6915 - val_loss: 0.8035 - val_accuracy: 0.8409

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.8035154662132263
Test accuracy: 0.8409000039100647
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2742 - accuracy: 0.1398 - val_loss: 2.2325 - val_accuracy: 0.2332
Epoch 2/12
 - 3s - loss: 2.2075 - accuracy: 0.2369 - val_loss: 2.1476 - val_accuracy: 0.4361
Epoch 3/12
 - 3s - loss: 2.1182 - accuracy: 0.3452 - val_loss: 2.0334 - val_accuracy: 0.5488
Epoch 4/12
 - 3s - loss: 1.9993 - accuracy: 0.4383 - val_loss: 1.8813 - val_accuracy: 0.6328

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8489 - accuracy: 0.5091 - val_loss: 1.6934 - val_accuracy: 0.6997

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.6760 - accuracy: 0.5666 - val_loss: 1.4848 - val_accuracy: 0.7492

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.5012 - accuracy: 0.6076 - val_loss: 1.2819 - val_accuracy: 0.7800

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.3407 - accuracy: 0.6373 - val_loss: 1.1048 - val_accuracy: 0.8018

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.2092 - accuracy: 0.6645 - val_loss: 0.9620 - val_accuracy: 0.8160

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.1018 - accuracy: 0.6855 - val_loss: 0.8520 - val_accuracy: 0.8271

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0193 - accuracy: 0.7008 - val_loss: 0.7683 - val_accuracy: 0.8369

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9490 - accuracy: 0.7187 - val_loss: 0.7026 - val_accuracy: 0.8440

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7026355759620666
Test accuracy: 0.843999981880188
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2895 - accuracy: 0.1297 - val_loss: 2.2603 - val_accuracy: 0.2514
Epoch 2/12
 - 3s - loss: 2.2450 - accuracy: 0.2139 - val_loss: 2.2077 - val_accuracy: 0.4303
Epoch 3/12
 - 3s - loss: 2.1907 - accuracy: 0.3095 - val_loss: 2.1395 - val_accuracy: 0.5292
Epoch 4/12
 - 3s - loss: 2.1171 - accuracy: 0.3946 - val_loss: 2.0451 - val_accuracy: 0.5966

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 2.0179 - accuracy: 0.4636 - val_loss: 1.9179 - val_accuracy: 0.6571

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.8893 - accuracy: 0.5158 - val_loss: 1.7545 - val_accuracy: 0.7119

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.7314 - accuracy: 0.5599 - val_loss: 1.5557 - val_accuracy: 0.7488

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.5579 - accuracy: 0.5958 - val_loss: 1.3434 - val_accuracy: 0.7813

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.3866 - accuracy: 0.6272 - val_loss: 1.1486 - val_accuracy: 0.7992

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2421 - accuracy: 0.6533 - val_loss: 0.9904 - val_accuracy: 0.8135

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.1245 - accuracy: 0.6784 - val_loss: 0.8695 - val_accuracy: 0.8230

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0332 - accuracy: 0.6962 - val_loss: 0.7784 - val_accuracy: 0.8299

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.778400238609314
Test accuracy: 0.8299000263214111
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2755 - accuracy: 0.1585 - val_loss: 2.2340 - val_accuracy: 0.3846
Epoch 2/12
 - 3s - loss: 2.2088 - accuracy: 0.2881 - val_loss: 2.1486 - val_accuracy: 0.5876
Epoch 3/12
 - 3s - loss: 2.1164 - accuracy: 0.4099 - val_loss: 2.0302 - val_accuracy: 0.6659
Epoch 4/12
 - 3s - loss: 1.9946 - accuracy: 0.4969 - val_loss: 1.8720 - val_accuracy: 0.7172

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.8379 - accuracy: 0.5551 - val_loss: 1.6749 - val_accuracy: 0.7598

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.6521 - accuracy: 0.5994 - val_loss: 1.4536 - val_accuracy: 0.7902

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.4641 - accuracy: 0.6299 - val_loss: 1.2395 - val_accuracy: 0.8101

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.2956 - accuracy: 0.6581 - val_loss: 1.0570 - val_accuracy: 0.8192

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.1649 - accuracy: 0.6791 - val_loss: 0.9148 - val_accuracy: 0.8325

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.0544 - accuracy: 0.7009 - val_loss: 0.8066 - val_accuracy: 0.8407

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 0.9722 - accuracy: 0.7165 - val_loss: 0.7261 - val_accuracy: 0.8477

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 0.9095 - accuracy: 0.7304 - val_loss: 0.6638 - val_accuracy: 0.8537

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.6637833371162415
Test accuracy: 0.8536999821662903
Train on 60000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/12
 - 3s - loss: 2.2858 - accuracy: 0.1312 - val_loss: 2.2532 - val_accuracy: 0.2398
Epoch 2/12
 - 3s - loss: 2.2330 - accuracy: 0.2379 - val_loss: 2.1905 - val_accuracy: 0.5004
Epoch 3/12
 - 3s - loss: 2.1688 - accuracy: 0.3509 - val_loss: 2.1113 - val_accuracy: 0.6114
Epoch 4/12
 - 3s - loss: 2.0858 - accuracy: 0.4389 - val_loss: 2.0073 - val_accuracy: 0.6699

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 5/12
 - 3s - loss: 1.9764 - accuracy: 0.5079 - val_loss: 1.8704 - val_accuracy: 0.7060

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 6/12
 - 3s - loss: 1.8404 - accuracy: 0.5551 - val_loss: 1.6987 - val_accuracy: 0.7381

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 7/12
 - 3s - loss: 1.6761 - accuracy: 0.5879 - val_loss: 1.4979 - val_accuracy: 0.7624

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 8/12
 - 3s - loss: 1.5024 - accuracy: 0.6144 - val_loss: 1.2945 - val_accuracy: 0.7806

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 9/12
 - 3s - loss: 1.3420 - accuracy: 0.6414 - val_loss: 1.1132 - val_accuracy: 0.7979

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 10/12
 - 3s - loss: 1.2082 - accuracy: 0.6618 - val_loss: 0.9681 - val_accuracy: 0.8125

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 11/12
 - 3s - loss: 1.0947 - accuracy: 0.6859 - val_loss: 0.8546 - val_accuracy: 0.8249

Umlaut results:
[<Warning: Check validation accuracy>]
Epoch 12/12
 - 3s - loss: 1.0164 - accuracy: 0.6995 - val_loss: 0.7697 - val_accuracy: 0.8351

Umlaut results:
[<Warning: Check validation accuracy>]
Test loss: 0.7696996516227722
Test accuracy: 0.835099995136261

Process finished with exit code 0
