D:\nargiz\github\umlaut\venvUMLT\Scripts\python.exe D:/nargiz/github/umlaut/cifar10_change_epochs_1.py
Using TensorFlow backend.
2023-03-19 18:26:02.296093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2023-03-19 18:26:07.600221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2023-03-19 18:26:07.627446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0b:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-19 18:26:07.627619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2023-03-19 18:26:08.059502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2023-03-19 18:26:08.111157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2023-03-19 18:26:08.142087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2023-03-19 18:26:08.374156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2023-03-19 18:26:08.590606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2023-03-19 18:26:08.806346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2023-03-19 18:26:08.806482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2023-03-19 18:26:08.806780: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2023-03-19 18:26:08.807635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0b:00.0 name: NVIDIA GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.65GHz coreCount: 34 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2023-03-19 18:26:08.807818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2023-03-19 18:26:08.807898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2023-03-19 18:26:08.807971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2023-03-19 18:26:08.808046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2023-03-19 18:26:08.808123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2023-03-19 18:26:08.808211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2023-03-19 18:26:08.808286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2023-03-19 18:26:08.808373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2023-03-19 18:26:09.274833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-03-19 18:26:09.274931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2023-03-19 18:26:09.274988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2023-03-19 18:26:09.275134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6704 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:0b:00.0, compute capability: 7.5)
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1
2023-03-19 18:26:11.216655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2023-03-19 18:26:11.403706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2023-03-19 18:26:12.139810: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.

   64/40000 [..............................] - ETA: 12:23 - loss: 2.2992 - accuracy: 0.0781
  832/40000 [..............................] - ETA: 58s - loss: 2.3023 - accuracy: 0.1034  
 1664/40000 [>.............................] - ETA: 29s - loss: 2.2665 - accuracy: 0.1466
 2432/40000 [>.............................] - ETA: 20s - loss: 2.2290 - accuracy: 0.1657
 3264/40000 [=>............................] - ETA: 15s - loss: 2.1950 - accuracy: 0.1746
 4160/40000 [==>...........................] - ETA: 12s - loss: 2.1706 - accuracy: 0.1825
 5056/40000 [==>...........................] - ETA: 10s - loss: 2.1482 - accuracy: 0.1897
 5888/40000 [===>..........................] - ETA: 8s - loss: 2.1261 - accuracy: 0.2002 
 6720/40000 [====>.........................] - ETA: 7s - loss: 2.1060 - accuracy: 0.2079
 7552/40000 [====>.........................] - ETA: 7s - loss: 2.0913 - accuracy: 0.2132
 8448/40000 [=====>........................] - ETA: 6s - loss: 2.0739 - accuracy: 0.2208
 9344/40000 [======>.......................] - ETA: 5s - loss: 2.0520 - accuracy: 0.2315
10240/40000 [======>.......................] - ETA: 5s - loss: 2.0307 - accuracy: 0.2386
11072/40000 [=======>......................] - ETA: 4s - loss: 2.0101 - accuracy: 0.2442
11968/40000 [=======>......................] - ETA: 4s - loss: 1.9880 - accuracy: 0.2523
12864/40000 [========>.....................] - ETA: 4s - loss: 1.9718 - accuracy: 0.2575
13760/40000 [=========>....................] - ETA: 3s - loss: 1.9573 - accuracy: 0.2632
14592/40000 [=========>....................] - ETA: 3s - loss: 1.9403 - accuracy: 0.2709
15424/40000 [==========>...................] - ETA: 3s - loss: 1.9265 - accuracy: 0.2766
16256/40000 [===========>..................] - ETA: 3s - loss: 1.9177 - accuracy: 0.2811
17152/40000 [===========>..................] - ETA: 2s - loss: 1.9033 - accuracy: 0.2870
18048/40000 [============>.................] - ETA: 2s - loss: 1.8893 - accuracy: 0.2926
18944/40000 [=============>................] - ETA: 2s - loss: 1.8795 - accuracy: 0.2966
19776/40000 [=============>................] - ETA: 2s - loss: 1.8682 - accuracy: 0.3012
20672/40000 [==============>...............] - ETA: 2s - loss: 1.8533 - accuracy: 0.3072
21568/40000 [===============>..............] - ETA: 2s - loss: 1.8401 - accuracy: 0.3129
22400/40000 [===============>..............] - ETA: 1s - loss: 1.8268 - accuracy: 0.3176
23232/40000 [================>.............] - ETA: 1s - loss: 1.8170 - accuracy: 0.3224
24064/40000 [=================>............] - ETA: 1s - loss: 1.8054 - accuracy: 0.3266
24896/40000 [=================>............] - ETA: 1s - loss: 1.7942 - accuracy: 0.3313
25792/40000 [==================>...........] - ETA: 1s - loss: 1.7845 - accuracy: 0.3358
26752/40000 [===================>..........] - ETA: 1s - loss: 1.7761 - accuracy: 0.3392
27648/40000 [===================>..........] - ETA: 1s - loss: 1.7668 - accuracy: 0.3422
28480/40000 [====================>.........] - ETA: 1s - loss: 1.7589 - accuracy: 0.3455
29312/40000 [====================>.........] - ETA: 1s - loss: 1.7500 - accuracy: 0.3493
30208/40000 [=====================>........] - ETA: 0s - loss: 1.7416 - accuracy: 0.3529
31104/40000 [======================>.......] - ETA: 0s - loss: 1.7317 - accuracy: 0.3576
31936/40000 [======================>.......] - ETA: 0s - loss: 1.7240 - accuracy: 0.3606
32832/40000 [=======================>......] - ETA: 0s - loss: 1.7168 - accuracy: 0.3635
33728/40000 [========================>.....] - ETA: 0s - loss: 1.7071 - accuracy: 0.3671
34624/40000 [========================>.....] - ETA: 0s - loss: 1.6985 - accuracy: 0.3704
35520/40000 [=========================>....] - ETA: 0s - loss: 1.6897 - accuracy: 0.3740
36352/40000 [==========================>...] - ETA: 0s - loss: 1.6824 - accuracy: 0.3768
37184/40000 [==========================>...] - ETA: 0s - loss: 1.6747 - accuracy: 0.3797
37952/40000 [===========================>..] - ETA: 0s - loss: 1.6668 - accuracy: 0.3827
38720/40000 [============================>.] - ETA: 0s - loss: 1.6600 - accuracy: 0.3858
39488/40000 [============================>.] - ETA: 0s - loss: 1.6545 - accuracy: 0.3883
40000/40000 [==============================] - 4s 101us/step - loss: 1.6515 - accuracy: 0.3895 - val_loss: 1.3978 - val_accuracy: 0.4965
Score [1.4086603452682496, 0.49779999256134033]
test data shape (10000, 32, 32, 3)
Loss: 1.4086603452682496 / Accuracy: 0.49779999256134033
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:24 - loss: 2.2918 - accuracy: 0.1562
  704/40000 [..............................] - ETA: 10s - loss: 2.2922 - accuracy: 0.1207 
 1344/40000 [>.............................] - ETA: 7s - loss: 2.2558 - accuracy: 0.1443 
 1920/40000 [>.............................] - ETA: 5s - loss: 2.2021 - accuracy: 0.1693
 2624/40000 [>.............................] - ETA: 4s - loss: 2.1715 - accuracy: 0.1803
 3264/40000 [=>............................] - ETA: 4s - loss: 2.1278 - accuracy: 0.1955
 3968/40000 [=>............................] - ETA: 4s - loss: 2.0978 - accuracy: 0.2056
 4672/40000 [==>...........................] - ETA: 3s - loss: 2.0735 - accuracy: 0.2200
 5440/40000 [===>..........................] - ETA: 3s - loss: 2.0423 - accuracy: 0.2316
 6208/40000 [===>..........................] - ETA: 3s - loss: 2.0110 - accuracy: 0.2440
 6976/40000 [====>.........................] - ETA: 3s - loss: 1.9859 - accuracy: 0.2519
 7872/40000 [====>.........................] - ETA: 2s - loss: 1.9646 - accuracy: 0.2614
 8704/40000 [=====>........................] - ETA: 2s - loss: 1.9449 - accuracy: 0.2676
 9536/40000 [======>.......................] - ETA: 2s - loss: 1.9262 - accuracy: 0.2740
10368/40000 [======>.......................] - ETA: 2s - loss: 1.9103 - accuracy: 0.2796
11264/40000 [=======>......................] - ETA: 2s - loss: 1.8901 - accuracy: 0.2880
12160/40000 [========>.....................] - ETA: 2s - loss: 1.8778 - accuracy: 0.2961
13056/40000 [========>.....................] - ETA: 2s - loss: 1.8640 - accuracy: 0.3024
13952/40000 [=========>....................] - ETA: 2s - loss: 1.8489 - accuracy: 0.3099
14848/40000 [==========>...................] - ETA: 1s - loss: 1.8381 - accuracy: 0.3133
15744/40000 [==========>...................] - ETA: 1s - loss: 1.8250 - accuracy: 0.3192
16576/40000 [===========>..................] - ETA: 1s - loss: 1.8113 - accuracy: 0.3250
17472/40000 [============>.................] - ETA: 1s - loss: 1.8011 - accuracy: 0.3296
18304/40000 [============>.................] - ETA: 1s - loss: 1.7899 - accuracy: 0.3340
19200/40000 [=============>................] - ETA: 1s - loss: 1.7806 - accuracy: 0.3387
20032/40000 [==============>...............] - ETA: 1s - loss: 1.7705 - accuracy: 0.3424
20864/40000 [==============>...............] - ETA: 1s - loss: 1.7604 - accuracy: 0.3468
21696/40000 [===============>..............] - ETA: 1s - loss: 1.7508 - accuracy: 0.3507
22528/40000 [===============>..............] - ETA: 1s - loss: 1.7405 - accuracy: 0.3545
23296/40000 [================>.............] - ETA: 1s - loss: 1.7326 - accuracy: 0.3575
24064/40000 [=================>............] - ETA: 1s - loss: 1.7258 - accuracy: 0.3608
24832/40000 [=================>............] - ETA: 1s - loss: 1.7204 - accuracy: 0.3621
25536/40000 [==================>...........] - ETA: 1s - loss: 1.7146 - accuracy: 0.3638
26368/40000 [==================>...........] - ETA: 0s - loss: 1.7083 - accuracy: 0.3660
27136/40000 [===================>..........] - ETA: 0s - loss: 1.6984 - accuracy: 0.3699
27904/40000 [===================>..........] - ETA: 0s - loss: 1.6925 - accuracy: 0.3725
28736/40000 [====================>.........] - ETA: 0s - loss: 1.6857 - accuracy: 0.3748
29632/40000 [=====================>........] - ETA: 0s - loss: 1.6775 - accuracy: 0.3783
30528/40000 [=====================>........] - ETA: 0s - loss: 1.6706 - accuracy: 0.3809
31360/40000 [======================>.......] - ETA: 0s - loss: 1.6658 - accuracy: 0.3830
32128/40000 [=======================>......] - ETA: 0s - loss: 1.6604 - accuracy: 0.3858
32896/40000 [=======================>......] - ETA: 0s - loss: 1.6538 - accuracy: 0.3883
33664/40000 [========================>.....] - ETA: 0s - loss: 1.6481 - accuracy: 0.3911
34560/40000 [========================>.....] - ETA: 0s - loss: 1.6413 - accuracy: 0.3939
35456/40000 [=========================>....] - ETA: 0s - loss: 1.6362 - accuracy: 0.3961
36288/40000 [==========================>...] - ETA: 0s - loss: 1.6323 - accuracy: 0.3976
37184/40000 [==========================>...] - ETA: 0s - loss: 1.6263 - accuracy: 0.3997
38080/40000 [===========================>..] - ETA: 0s - loss: 1.6209 - accuracy: 0.4020
38976/40000 [============================>.] - ETA: 0s - loss: 1.6150 - accuracy: 0.4045
39808/40000 [============================>.] - ETA: 0s - loss: 1.6078 - accuracy: 0.4070
40000/40000 [==============================] - 3s 77us/step - loss: 1.6070 - accuracy: 0.4076 - val_loss: 1.3073 - val_accuracy: 0.5187
Score [1.3179748113632201, 0.5109999775886536]
test data shape (10000, 32, 32, 3)
Loss: 1.3179748113632201 / Accuracy: 0.5109999775886536
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:25 - loss: 2.3252 - accuracy: 0.0938
  640/40000 [..............................] - ETA: 11s - loss: 2.3041 - accuracy: 0.1172 
 1216/40000 [..............................] - ETA: 7s - loss: 2.2899 - accuracy: 0.1357 
 1856/40000 [>.............................] - ETA: 6s - loss: 2.2537 - accuracy: 0.1498
 2432/40000 [>.............................] - ETA: 5s - loss: 2.2196 - accuracy: 0.1608
 3072/40000 [=>............................] - ETA: 4s - loss: 2.2037 - accuracy: 0.1663
 3776/40000 [=>............................] - ETA: 4s - loss: 2.1742 - accuracy: 0.1822
 4544/40000 [==>...........................] - ETA: 3s - loss: 2.1487 - accuracy: 0.1862
 5312/40000 [==>...........................] - ETA: 3s - loss: 2.1366 - accuracy: 0.1884
 6016/40000 [===>..........................] - ETA: 3s - loss: 2.1169 - accuracy: 0.1968
 6720/40000 [====>.........................] - ETA: 3s - loss: 2.0954 - accuracy: 0.2085
 7488/40000 [====>.........................] - ETA: 3s - loss: 2.0753 - accuracy: 0.2170
 8192/40000 [=====>........................] - ETA: 2s - loss: 2.0541 - accuracy: 0.2271
 8960/40000 [=====>........................] - ETA: 2s - loss: 2.0360 - accuracy: 0.2353
 9728/40000 [======>.......................] - ETA: 2s - loss: 2.0196 - accuracy: 0.2416
10496/40000 [======>.......................] - ETA: 2s - loss: 1.9986 - accuracy: 0.2498
11264/40000 [=======>......................] - ETA: 2s - loss: 1.9810 - accuracy: 0.2547
12032/40000 [========>.....................] - ETA: 2s - loss: 1.9677 - accuracy: 0.2598
12864/40000 [========>.....................] - ETA: 2s - loss: 1.9526 - accuracy: 0.2649
13696/40000 [=========>....................] - ETA: 2s - loss: 1.9407 - accuracy: 0.2696
14592/40000 [=========>....................] - ETA: 2s - loss: 1.9250 - accuracy: 0.2741
15424/40000 [==========>...................] - ETA: 1s - loss: 1.9091 - accuracy: 0.2807
16192/40000 [===========>..................] - ETA: 1s - loss: 1.8965 - accuracy: 0.2855
16960/40000 [===========>..................] - ETA: 1s - loss: 1.8858 - accuracy: 0.2901
17728/40000 [============>.................] - ETA: 1s - loss: 1.8741 - accuracy: 0.2942
18496/40000 [============>.................] - ETA: 1s - loss: 1.8613 - accuracy: 0.2996
19200/40000 [=============>................] - ETA: 1s - loss: 1.8523 - accuracy: 0.3030
19904/40000 [=============>................] - ETA: 1s - loss: 1.8426 - accuracy: 0.3072
20608/40000 [==============>...............] - ETA: 1s - loss: 1.8346 - accuracy: 0.3110
21312/40000 [==============>...............] - ETA: 1s - loss: 1.8268 - accuracy: 0.3145
22080/40000 [===============>..............] - ETA: 1s - loss: 1.8136 - accuracy: 0.3195
22784/40000 [================>.............] - ETA: 1s - loss: 1.8056 - accuracy: 0.3226
23488/40000 [================>.............] - ETA: 1s - loss: 1.7957 - accuracy: 0.3262
24256/40000 [=================>............] - ETA: 1s - loss: 1.7867 - accuracy: 0.3297
24960/40000 [=================>............] - ETA: 1s - loss: 1.7775 - accuracy: 0.3333
25664/40000 [==================>...........] - ETA: 1s - loss: 1.7679 - accuracy: 0.3367
26432/40000 [==================>...........] - ETA: 1s - loss: 1.7603 - accuracy: 0.3396
27200/40000 [===================>..........] - ETA: 0s - loss: 1.7518 - accuracy: 0.3433
27968/40000 [===================>..........] - ETA: 0s - loss: 1.7426 - accuracy: 0.3473
28736/40000 [====================>.........] - ETA: 0s - loss: 1.7352 - accuracy: 0.3504
29568/40000 [=====================>........] - ETA: 0s - loss: 1.7265 - accuracy: 0.3543
30464/40000 [=====================>........] - ETA: 0s - loss: 1.7163 - accuracy: 0.3585
31360/40000 [======================>.......] - ETA: 0s - loss: 1.7083 - accuracy: 0.3619
32192/40000 [=======================>......] - ETA: 0s - loss: 1.7013 - accuracy: 0.3644
33024/40000 [=======================>......] - ETA: 0s - loss: 1.6939 - accuracy: 0.3671
33856/40000 [========================>.....] - ETA: 0s - loss: 1.6873 - accuracy: 0.3702
34688/40000 [=========================>....] - ETA: 0s - loss: 1.6789 - accuracy: 0.3736
35520/40000 [=========================>....] - ETA: 0s - loss: 1.6724 - accuracy: 0.3763
36352/40000 [==========================>...] - ETA: 0s - loss: 1.6670 - accuracy: 0.3789
37184/40000 [==========================>...] - ETA: 0s - loss: 1.6611 - accuracy: 0.3813
37952/40000 [===========================>..] - ETA: 0s - loss: 1.6546 - accuracy: 0.3842
38720/40000 [============================>.] - ETA: 0s - loss: 1.6496 - accuracy: 0.3859
39424/40000 [============================>.] - ETA: 0s - loss: 1.6454 - accuracy: 0.3874
40000/40000 [==============================] - 3s 83us/step - loss: 1.6407 - accuracy: 0.3894 - val_loss: 1.3104 - val_accuracy: 0.5288
Score [1.3122726974487304, 0.5271999835968018]
test data shape (10000, 32, 32, 3)
Loss: 1.3122726974487304 / Accuracy: 0.5271999835968018
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:20 - loss: 2.2906 - accuracy: 0.1094
  768/40000 [..............................] - ETA: 9s - loss: 2.2964 - accuracy: 0.1250  
 1408/40000 [>.............................] - ETA: 6s - loss: 2.2841 - accuracy: 0.1214
 2048/40000 [>.............................] - ETA: 5s - loss: 2.2643 - accuracy: 0.1416
 2624/40000 [>.............................] - ETA: 4s - loss: 2.2301 - accuracy: 0.1570
 3392/40000 [=>............................] - ETA: 4s - loss: 2.1763 - accuracy: 0.1822
 4224/40000 [==>...........................] - ETA: 3s - loss: 2.1352 - accuracy: 0.1984
 4992/40000 [==>...........................] - ETA: 3s - loss: 2.0996 - accuracy: 0.2131
 5824/40000 [===>..........................] - ETA: 3s - loss: 2.0662 - accuracy: 0.2242
 6656/40000 [===>..........................] - ETA: 3s - loss: 2.0334 - accuracy: 0.2336
 7552/40000 [====>.........................] - ETA: 2s - loss: 2.0081 - accuracy: 0.2436
 8384/40000 [=====>........................] - ETA: 2s - loss: 1.9846 - accuracy: 0.2536
 9280/40000 [=====>........................] - ETA: 2s - loss: 1.9594 - accuracy: 0.2631
10112/40000 [======>.......................] - ETA: 2s - loss: 1.9367 - accuracy: 0.2723
11008/40000 [=======>......................] - ETA: 2s - loss: 1.9217 - accuracy: 0.2786
11904/40000 [=======>......................] - ETA: 2s - loss: 1.9028 - accuracy: 0.2867
12736/40000 [========>.....................] - ETA: 2s - loss: 1.8899 - accuracy: 0.2931
13568/40000 [=========>....................] - ETA: 1s - loss: 1.8707 - accuracy: 0.3004
14464/40000 [=========>....................] - ETA: 1s - loss: 1.8504 - accuracy: 0.3072
15360/40000 [==========>...................] - ETA: 1s - loss: 1.8340 - accuracy: 0.3137
16256/40000 [===========>..................] - ETA: 1s - loss: 1.8191 - accuracy: 0.3185
17088/40000 [===========>..................] - ETA: 1s - loss: 1.8071 - accuracy: 0.3234
17920/40000 [============>.................] - ETA: 1s - loss: 1.7940 - accuracy: 0.3283
18752/40000 [=============>................] - ETA: 1s - loss: 1.7841 - accuracy: 0.3335
19648/40000 [=============>................] - ETA: 1s - loss: 1.7724 - accuracy: 0.3386
20544/40000 [==============>...............] - ETA: 1s - loss: 1.7598 - accuracy: 0.3440
21440/40000 [===============>..............] - ETA: 1s - loss: 1.7494 - accuracy: 0.3480
22272/40000 [===============>..............] - ETA: 1s - loss: 1.7401 - accuracy: 0.3514
23168/40000 [================>.............] - ETA: 1s - loss: 1.7290 - accuracy: 0.3562
24064/40000 [=================>............] - ETA: 1s - loss: 1.7177 - accuracy: 0.3606
24960/40000 [=================>............] - ETA: 1s - loss: 1.7056 - accuracy: 0.3655
25792/40000 [==================>...........] - ETA: 0s - loss: 1.6960 - accuracy: 0.3702
26624/40000 [==================>...........] - ETA: 0s - loss: 1.6891 - accuracy: 0.3733
27456/40000 [===================>..........] - ETA: 0s - loss: 1.6812 - accuracy: 0.3761
28352/40000 [====================>.........] - ETA: 0s - loss: 1.6722 - accuracy: 0.3791
29248/40000 [====================>.........] - ETA: 0s - loss: 1.6644 - accuracy: 0.3821
30080/40000 [=====================>........] - ETA: 0s - loss: 1.6558 - accuracy: 0.3853
30912/40000 [======================>.......] - ETA: 0s - loss: 1.6491 - accuracy: 0.3876
31808/40000 [======================>.......] - ETA: 0s - loss: 1.6427 - accuracy: 0.3903
32704/40000 [=======================>......] - ETA: 0s - loss: 1.6347 - accuracy: 0.3931
33600/40000 [========================>.....] - ETA: 0s - loss: 1.6275 - accuracy: 0.3958
34496/40000 [========================>.....] - ETA: 0s - loss: 1.6214 - accuracy: 0.3988
35328/40000 [=========================>....] - ETA: 0s - loss: 1.6159 - accuracy: 0.4010
36224/40000 [==========================>...] - ETA: 0s - loss: 1.6093 - accuracy: 0.4037
37120/40000 [==========================>...] - ETA: 0s - loss: 1.6037 - accuracy: 0.4061
38016/40000 [===========================>..] - ETA: 0s - loss: 1.5971 - accuracy: 0.4093
38848/40000 [============================>.] - ETA: 0s - loss: 1.5913 - accuracy: 0.4113
39680/40000 [============================>.] - ETA: 0s - loss: 1.5868 - accuracy: 0.4134
40000/40000 [==============================] - 3s 74us/step - loss: 1.5852 - accuracy: 0.4139 - val_loss: 1.2755 - val_accuracy: 0.5371
Score [1.2751192390441894, 0.5400000214576721]
test data shape (10000, 32, 32, 3)
Loss: 1.2751192390441894 / Accuracy: 0.5400000214576721
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:20 - loss: 2.3110 - accuracy: 0.0938
  704/40000 [..............................] - ETA: 10s - loss: 2.3003 - accuracy: 0.1222 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2938 - accuracy: 0.1156 
 1856/40000 [>.............................] - ETA: 6s - loss: 2.2704 - accuracy: 0.1347
 2560/40000 [>.............................] - ETA: 5s - loss: 2.2316 - accuracy: 0.1598
 3328/40000 [=>............................] - ETA: 4s - loss: 2.1992 - accuracy: 0.1683
 4096/40000 [==>...........................] - ETA: 3s - loss: 2.1746 - accuracy: 0.1809
 4800/40000 [==>...........................] - ETA: 3s - loss: 2.1487 - accuracy: 0.1912
 5568/40000 [===>..........................] - ETA: 3s - loss: 2.1217 - accuracy: 0.1999
 6336/40000 [===>..........................] - ETA: 3s - loss: 2.0942 - accuracy: 0.2137
 7232/40000 [====>.........................] - ETA: 2s - loss: 2.0675 - accuracy: 0.2221
 8064/40000 [=====>........................] - ETA: 2s - loss: 2.0377 - accuracy: 0.2325
 8896/40000 [=====>........................] - ETA: 2s - loss: 2.0107 - accuracy: 0.2430
 9728/40000 [======>.......................] - ETA: 2s - loss: 1.9933 - accuracy: 0.2499
10624/40000 [======>.......................] - ETA: 2s - loss: 1.9703 - accuracy: 0.2603
11520/40000 [=======>......................] - ETA: 2s - loss: 1.9559 - accuracy: 0.2648
12416/40000 [========>.....................] - ETA: 2s - loss: 1.9374 - accuracy: 0.2736
13248/40000 [========>.....................] - ETA: 2s - loss: 1.9198 - accuracy: 0.2800
14080/40000 [=========>....................] - ETA: 1s - loss: 1.9014 - accuracy: 0.2869
14912/40000 [==========>...................] - ETA: 1s - loss: 1.8863 - accuracy: 0.2936
15808/40000 [==========>...................] - ETA: 1s - loss: 1.8732 - accuracy: 0.2997
16704/40000 [===========>..................] - ETA: 1s - loss: 1.8619 - accuracy: 0.3035
17536/40000 [============>.................] - ETA: 1s - loss: 1.8516 - accuracy: 0.3071
18368/40000 [============>.................] - ETA: 1s - loss: 1.8409 - accuracy: 0.3106
19264/40000 [=============>................] - ETA: 1s - loss: 1.8265 - accuracy: 0.3170
20160/40000 [==============>...............] - ETA: 1s - loss: 1.8157 - accuracy: 0.3223
21056/40000 [==============>...............] - ETA: 1s - loss: 1.8033 - accuracy: 0.3279
21888/40000 [===============>..............] - ETA: 1s - loss: 1.7939 - accuracy: 0.3321
22784/40000 [================>.............] - ETA: 1s - loss: 1.7846 - accuracy: 0.3366
23680/40000 [================>.............] - ETA: 1s - loss: 1.7740 - accuracy: 0.3402
24576/40000 [=================>............] - ETA: 1s - loss: 1.7628 - accuracy: 0.3452
25536/40000 [==================>...........] - ETA: 0s - loss: 1.7557 - accuracy: 0.3484
26432/40000 [==================>...........] - ETA: 0s - loss: 1.7459 - accuracy: 0.3518
27264/40000 [===================>..........] - ETA: 0s - loss: 1.7361 - accuracy: 0.3568
28160/40000 [====================>.........] - ETA: 0s - loss: 1.7274 - accuracy: 0.3602
29056/40000 [====================>.........] - ETA: 0s - loss: 1.7180 - accuracy: 0.3637
29952/40000 [=====================>........] - ETA: 0s - loss: 1.7108 - accuracy: 0.3668
30784/40000 [======================>.......] - ETA: 0s - loss: 1.7039 - accuracy: 0.3691
31680/40000 [======================>.......] - ETA: 0s - loss: 1.6951 - accuracy: 0.3725
32576/40000 [=======================>......] - ETA: 0s - loss: 1.6882 - accuracy: 0.3754
33472/40000 [========================>.....] - ETA: 0s - loss: 1.6805 - accuracy: 0.3784
34304/40000 [========================>.....] - ETA: 0s - loss: 1.6732 - accuracy: 0.3816
35136/40000 [=========================>....] - ETA: 0s - loss: 1.6672 - accuracy: 0.3839
35968/40000 [=========================>....] - ETA: 0s - loss: 1.6612 - accuracy: 0.3868
36864/40000 [==========================>...] - ETA: 0s - loss: 1.6537 - accuracy: 0.3897
37824/40000 [===========================>..] - ETA: 0s - loss: 1.6471 - accuracy: 0.3921
38720/40000 [============================>.] - ETA: 0s - loss: 1.6411 - accuracy: 0.3946
39552/40000 [============================>.] - ETA: 0s - loss: 1.6360 - accuracy: 0.3965
40000/40000 [==============================] - 3s 74us/step - loss: 1.6337 - accuracy: 0.3975 - val_loss: 1.3262 - val_accuracy: 0.5159
Score [1.3331563968658446, 0.5080000162124634]
test data shape (10000, 32, 32, 3)
Loss: 1.3331563968658446 / Accuracy: 0.5080000162124634
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3157 - accuracy: 0.0469
  704/40000 [..............................] - ETA: 10s - loss: 2.3004 - accuracy: 0.0980 
 1344/40000 [>.............................] - ETA: 6s - loss: 2.2833 - accuracy: 0.1324 
 1920/40000 [>.............................] - ETA: 5s - loss: 2.2506 - accuracy: 0.1521
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2262 - accuracy: 0.1671
 3136/40000 [=>............................] - ETA: 4s - loss: 2.2009 - accuracy: 0.1763
 3776/40000 [=>............................] - ETA: 4s - loss: 2.1759 - accuracy: 0.1883
 4544/40000 [==>...........................] - ETA: 3s - loss: 2.1526 - accuracy: 0.2011
 5312/40000 [==>...........................] - ETA: 3s - loss: 2.1243 - accuracy: 0.2088
 6080/40000 [===>..........................] - ETA: 3s - loss: 2.1002 - accuracy: 0.2183
 6912/40000 [====>.........................] - ETA: 3s - loss: 2.0849 - accuracy: 0.2234
 7808/40000 [====>.........................] - ETA: 2s - loss: 2.0599 - accuracy: 0.2349
 8640/40000 [=====>........................] - ETA: 2s - loss: 2.0423 - accuracy: 0.2395
 9536/40000 [======>.......................] - ETA: 2s - loss: 2.0189 - accuracy: 0.2477
10432/40000 [======>.......................] - ETA: 2s - loss: 1.9983 - accuracy: 0.2573
11328/40000 [=======>......................] - ETA: 2s - loss: 1.9797 - accuracy: 0.2643
12288/40000 [========>.....................] - ETA: 2s - loss: 1.9619 - accuracy: 0.2715
13184/40000 [========>.....................] - ETA: 2s - loss: 1.9449 - accuracy: 0.2766
14016/40000 [=========>....................] - ETA: 1s - loss: 1.9306 - accuracy: 0.2835
14848/40000 [==========>...................] - ETA: 1s - loss: 1.9116 - accuracy: 0.2912
15744/40000 [==========>...................] - ETA: 1s - loss: 1.8933 - accuracy: 0.2978
16640/40000 [===========>..................] - ETA: 1s - loss: 1.8809 - accuracy: 0.3009
17472/40000 [============>.................] - ETA: 1s - loss: 1.8702 - accuracy: 0.3046
18304/40000 [============>.................] - ETA: 1s - loss: 1.8610 - accuracy: 0.3098
19136/40000 [=============>................] - ETA: 1s - loss: 1.8510 - accuracy: 0.3139
20032/40000 [==============>...............] - ETA: 1s - loss: 1.8379 - accuracy: 0.3185
20928/40000 [==============>...............] - ETA: 1s - loss: 1.8268 - accuracy: 0.3231
21824/40000 [===============>..............] - ETA: 1s - loss: 1.8170 - accuracy: 0.3264
22720/40000 [================>.............] - ETA: 1s - loss: 1.8063 - accuracy: 0.3310
23552/40000 [================>.............] - ETA: 1s - loss: 1.7962 - accuracy: 0.3353
24448/40000 [=================>............] - ETA: 1s - loss: 1.7863 - accuracy: 0.3389
25344/40000 [==================>...........] - ETA: 1s - loss: 1.7777 - accuracy: 0.3429
26176/40000 [==================>...........] - ETA: 0s - loss: 1.7677 - accuracy: 0.3471
27008/40000 [===================>..........] - ETA: 0s - loss: 1.7609 - accuracy: 0.3490
27840/40000 [===================>..........] - ETA: 0s - loss: 1.7523 - accuracy: 0.3519
28736/40000 [====================>.........] - ETA: 0s - loss: 1.7450 - accuracy: 0.3547
29632/40000 [=====================>........] - ETA: 0s - loss: 1.7375 - accuracy: 0.3577
30464/40000 [=====================>........] - ETA: 0s - loss: 1.7284 - accuracy: 0.3612
31360/40000 [======================>.......] - ETA: 0s - loss: 1.7191 - accuracy: 0.3648
32256/40000 [=======================>......] - ETA: 0s - loss: 1.7110 - accuracy: 0.3677
33152/40000 [=======================>......] - ETA: 0s - loss: 1.7026 - accuracy: 0.3711
34048/40000 [========================>.....] - ETA: 0s - loss: 1.6940 - accuracy: 0.3748
34880/40000 [=========================>....] - ETA: 0s - loss: 1.6868 - accuracy: 0.3780
35776/40000 [=========================>....] - ETA: 0s - loss: 1.6792 - accuracy: 0.3807
36672/40000 [==========================>...] - ETA: 0s - loss: 1.6721 - accuracy: 0.3835
37568/40000 [===========================>..] - ETA: 0s - loss: 1.6652 - accuracy: 0.3863
38400/40000 [===========================>..] - ETA: 0s - loss: 1.6584 - accuracy: 0.3891
39232/40000 [============================>.] - ETA: 0s - loss: 1.6523 - accuracy: 0.3915
40000/40000 [==============================] - 3s 74us/step - loss: 1.6461 - accuracy: 0.3938 - val_loss: 1.3788 - val_accuracy: 0.5037
Score [1.3791266286849975, 0.5094000101089478]
test data shape (10000, 32, 32, 3)
Loss: 1.3791266286849975 / Accuracy: 0.5094000101089478
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.2827 - accuracy: 0.0938
  704/40000 [..............................] - ETA: 10s - loss: 2.3014 - accuracy: 0.1037 
 1344/40000 [>.............................] - ETA: 6s - loss: 2.2971 - accuracy: 0.1094 
 1856/40000 [>.............................] - ETA: 5s - loss: 2.2834 - accuracy: 0.1245
 2432/40000 [>.............................] - ETA: 5s - loss: 2.2574 - accuracy: 0.1386
 3200/40000 [=>............................] - ETA: 4s - loss: 2.2287 - accuracy: 0.1544
 3968/40000 [=>............................] - ETA: 4s - loss: 2.2042 - accuracy: 0.1686
 4736/40000 [==>...........................] - ETA: 3s - loss: 2.1809 - accuracy: 0.1761
 5440/40000 [===>..........................] - ETA: 3s - loss: 2.1572 - accuracy: 0.1860
 6272/40000 [===>..........................] - ETA: 3s - loss: 2.1269 - accuracy: 0.1983
 7168/40000 [====>.........................] - ETA: 3s - loss: 2.0892 - accuracy: 0.2162
 8064/40000 [=====>........................] - ETA: 2s - loss: 2.0548 - accuracy: 0.2272
 8896/40000 [=====>........................] - ETA: 2s - loss: 2.0285 - accuracy: 0.2377
 9792/40000 [======>.......................] - ETA: 2s - loss: 2.0089 - accuracy: 0.2458
10688/40000 [=======>......................] - ETA: 2s - loss: 1.9839 - accuracy: 0.2545
11584/40000 [=======>......................] - ETA: 2s - loss: 1.9595 - accuracy: 0.2645
12416/40000 [========>.....................] - ETA: 2s - loss: 1.9426 - accuracy: 0.2708
13248/40000 [========>.....................] - ETA: 2s - loss: 1.9210 - accuracy: 0.2784
14080/40000 [=========>....................] - ETA: 1s - loss: 1.9088 - accuracy: 0.2834
14976/40000 [==========>...................] - ETA: 1s - loss: 1.8948 - accuracy: 0.2887
15872/40000 [==========>...................] - ETA: 1s - loss: 1.8768 - accuracy: 0.2945
16704/40000 [===========>..................] - ETA: 1s - loss: 1.8634 - accuracy: 0.3000
17536/40000 [============>.................] - ETA: 1s - loss: 1.8481 - accuracy: 0.3059
18368/40000 [============>.................] - ETA: 1s - loss: 1.8322 - accuracy: 0.3128
19264/40000 [=============>................] - ETA: 1s - loss: 1.8209 - accuracy: 0.3176
20160/40000 [==============>...............] - ETA: 1s - loss: 1.8131 - accuracy: 0.3212
20992/40000 [==============>...............] - ETA: 1s - loss: 1.8029 - accuracy: 0.3255
21824/40000 [===============>..............] - ETA: 1s - loss: 1.7943 - accuracy: 0.3294
22656/40000 [===============>..............] - ETA: 1s - loss: 1.7833 - accuracy: 0.3333
23552/40000 [================>.............] - ETA: 1s - loss: 1.7750 - accuracy: 0.3367
24448/40000 [=================>............] - ETA: 1s - loss: 1.7640 - accuracy: 0.3408
25344/40000 [==================>...........] - ETA: 1s - loss: 1.7533 - accuracy: 0.3450
26176/40000 [==================>...........] - ETA: 0s - loss: 1.7440 - accuracy: 0.3491
27008/40000 [===================>..........] - ETA: 0s - loss: 1.7340 - accuracy: 0.3530
27904/40000 [===================>..........] - ETA: 0s - loss: 1.7250 - accuracy: 0.3569
28800/40000 [====================>.........] - ETA: 0s - loss: 1.7150 - accuracy: 0.3607
29632/40000 [=====================>........] - ETA: 0s - loss: 1.7084 - accuracy: 0.3633
30464/40000 [=====================>........] - ETA: 0s - loss: 1.7005 - accuracy: 0.3668
31360/40000 [======================>.......] - ETA: 0s - loss: 1.6919 - accuracy: 0.3702
32256/40000 [=======================>......] - ETA: 0s - loss: 1.6842 - accuracy: 0.3734
33152/40000 [=======================>......] - ETA: 0s - loss: 1.6764 - accuracy: 0.3763
34048/40000 [========================>.....] - ETA: 0s - loss: 1.6715 - accuracy: 0.3780
34880/40000 [=========================>....] - ETA: 0s - loss: 1.6641 - accuracy: 0.3810
35776/40000 [=========================>....] - ETA: 0s - loss: 1.6554 - accuracy: 0.3843
36672/40000 [==========================>...] - ETA: 0s - loss: 1.6492 - accuracy: 0.3865
37568/40000 [===========================>..] - ETA: 0s - loss: 1.6421 - accuracy: 0.3896
38400/40000 [===========================>..] - ETA: 0s - loss: 1.6365 - accuracy: 0.3912
39232/40000 [============================>.] - ETA: 0s - loss: 1.6302 - accuracy: 0.3938
40000/40000 [==============================] - 3s 74us/step - loss: 1.6249 - accuracy: 0.3963 - val_loss: 1.3128 - val_accuracy: 0.5316
Score [1.3166946092605591, 0.5248000025749207]
test data shape (10000, 32, 32, 3)
Loss: 1.3166946092605591 / Accuracy: 0.5248000025749207
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.2971 - accuracy: 0.1562
  704/40000 [..............................] - ETA: 10s - loss: 2.2953 - accuracy: 0.1378 
 1344/40000 [>.............................] - ETA: 6s - loss: 2.2850 - accuracy: 0.1384 
 1984/40000 [>.............................] - ETA: 5s - loss: 2.2523 - accuracy: 0.1507
 2560/40000 [>.............................] - ETA: 5s - loss: 2.2120 - accuracy: 0.1633
 3200/40000 [=>............................] - ETA: 4s - loss: 2.1856 - accuracy: 0.1731
 3904/40000 [=>............................] - ETA: 4s - loss: 2.1453 - accuracy: 0.1878
 4672/40000 [==>...........................] - ETA: 3s - loss: 2.1060 - accuracy: 0.2063
 5440/40000 [===>..........................] - ETA: 3s - loss: 2.0632 - accuracy: 0.2232
 6208/40000 [===>..........................] - ETA: 3s - loss: 2.0375 - accuracy: 0.2342
 7040/40000 [====>.........................] - ETA: 3s - loss: 2.0133 - accuracy: 0.2447
 7936/40000 [====>.........................] - ETA: 2s - loss: 1.9860 - accuracy: 0.2534
 8768/40000 [=====>........................] - ETA: 2s - loss: 1.9617 - accuracy: 0.2630
 9600/40000 [======>.......................] - ETA: 2s - loss: 1.9418 - accuracy: 0.2710
10496/40000 [======>.......................] - ETA: 2s - loss: 1.9241 - accuracy: 0.2781
11392/40000 [=======>......................] - ETA: 2s - loss: 1.9081 - accuracy: 0.2868
12288/40000 [========>.....................] - ETA: 2s - loss: 1.8935 - accuracy: 0.2924
13120/40000 [========>.....................] - ETA: 2s - loss: 1.8781 - accuracy: 0.2985
13952/40000 [=========>....................] - ETA: 2s - loss: 1.8677 - accuracy: 0.3032
14848/40000 [==========>...................] - ETA: 1s - loss: 1.8505 - accuracy: 0.3105
15680/40000 [==========>...................] - ETA: 1s - loss: 1.8369 - accuracy: 0.3156
16576/40000 [===========>..................] - ETA: 1s - loss: 1.8223 - accuracy: 0.3221
17408/40000 [============>.................] - ETA: 1s - loss: 1.8099 - accuracy: 0.3281
18304/40000 [============>.................] - ETA: 1s - loss: 1.7976 - accuracy: 0.3336
19136/40000 [=============>................] - ETA: 1s - loss: 1.7869 - accuracy: 0.3372
20032/40000 [==============>...............] - ETA: 1s - loss: 1.7771 - accuracy: 0.3408
20928/40000 [==============>...............] - ETA: 1s - loss: 1.7663 - accuracy: 0.3448
21760/40000 [===============>..............] - ETA: 1s - loss: 1.7559 - accuracy: 0.3483
22656/40000 [===============>..............] - ETA: 1s - loss: 1.7442 - accuracy: 0.3533
23488/40000 [================>.............] - ETA: 1s - loss: 1.7351 - accuracy: 0.3565
24384/40000 [=================>............] - ETA: 1s - loss: 1.7272 - accuracy: 0.3595
25280/40000 [=================>............] - ETA: 1s - loss: 1.7161 - accuracy: 0.3635
26112/40000 [==================>...........] - ETA: 0s - loss: 1.7080 - accuracy: 0.3667
26944/40000 [===================>..........] - ETA: 0s - loss: 1.6996 - accuracy: 0.3698
27776/40000 [===================>..........] - ETA: 0s - loss: 1.6912 - accuracy: 0.3723
28672/40000 [====================>.........] - ETA: 0s - loss: 1.6832 - accuracy: 0.3756
29568/40000 [=====================>........] - ETA: 0s - loss: 1.6766 - accuracy: 0.3783
30400/40000 [=====================>........] - ETA: 0s - loss: 1.6720 - accuracy: 0.3802
31296/40000 [======================>.......] - ETA: 0s - loss: 1.6661 - accuracy: 0.3833
32128/40000 [=======================>......] - ETA: 0s - loss: 1.6602 - accuracy: 0.3858
33024/40000 [=======================>......] - ETA: 0s - loss: 1.6529 - accuracy: 0.3884
33920/40000 [========================>.....] - ETA: 0s - loss: 1.6460 - accuracy: 0.3913
34752/40000 [=========================>....] - ETA: 0s - loss: 1.6396 - accuracy: 0.3939
35584/40000 [=========================>....] - ETA: 0s - loss: 1.6340 - accuracy: 0.3962
36416/40000 [==========================>...] - ETA: 0s - loss: 1.6293 - accuracy: 0.3978
37312/40000 [==========================>...] - ETA: 0s - loss: 1.6245 - accuracy: 0.3995
38208/40000 [===========================>..] - ETA: 0s - loss: 1.6184 - accuracy: 0.4026
39104/40000 [============================>.] - ETA: 0s - loss: 1.6110 - accuracy: 0.4057
39936/40000 [============================>.] - ETA: 0s - loss: 1.6059 - accuracy: 0.4079
40000/40000 [==============================] - 3s 74us/step - loss: 1.6054 - accuracy: 0.4080 - val_loss: 1.3920 - val_accuracy: 0.4918
Score [1.3986011728286742, 0.4945000112056732]
test data shape (10000, 32, 32, 3)
Loss: 1.3986011728286742 / Accuracy: 0.4945000112056732
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3046 - accuracy: 0.1406
  704/40000 [..............................] - ETA: 10s - loss: 2.2955 - accuracy: 0.1222 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2753 - accuracy: 0.1547 
 1792/40000 [>.............................] - ETA: 6s - loss: 2.2427 - accuracy: 0.1635
 2304/40000 [>.............................] - ETA: 5s - loss: 2.2194 - accuracy: 0.1697
 2944/40000 [=>............................] - ETA: 5s - loss: 2.1915 - accuracy: 0.1814
 3712/40000 [=>............................] - ETA: 4s - loss: 2.1510 - accuracy: 0.1937
 4416/40000 [==>...........................] - ETA: 4s - loss: 2.1255 - accuracy: 0.2045
 5120/40000 [==>...........................] - ETA: 3s - loss: 2.1043 - accuracy: 0.2137
 5888/40000 [===>..........................] - ETA: 3s - loss: 2.0751 - accuracy: 0.2249
 6720/40000 [====>.........................] - ETA: 3s - loss: 2.0531 - accuracy: 0.2333
 7552/40000 [====>.........................] - ETA: 3s - loss: 2.0341 - accuracy: 0.2410
 8320/40000 [=====>........................] - ETA: 2s - loss: 2.0144 - accuracy: 0.2496
 9152/40000 [=====>........................] - ETA: 2s - loss: 1.9947 - accuracy: 0.2587
 9984/40000 [======>.......................] - ETA: 2s - loss: 1.9750 - accuracy: 0.2678
10880/40000 [=======>......................] - ETA: 2s - loss: 1.9546 - accuracy: 0.2743
11776/40000 [=======>......................] - ETA: 2s - loss: 1.9352 - accuracy: 0.2823
12672/40000 [========>.....................] - ETA: 2s - loss: 1.9142 - accuracy: 0.2906
13504/40000 [=========>....................] - ETA: 2s - loss: 1.8959 - accuracy: 0.2967
14336/40000 [=========>....................] - ETA: 2s - loss: 1.8813 - accuracy: 0.3013
15232/40000 [==========>...................] - ETA: 1s - loss: 1.8709 - accuracy: 0.3060
16128/40000 [===========>..................] - ETA: 1s - loss: 1.8582 - accuracy: 0.3105
17024/40000 [===========>..................] - ETA: 1s - loss: 1.8443 - accuracy: 0.3163
17856/40000 [============>.................] - ETA: 1s - loss: 1.8310 - accuracy: 0.3213
18752/40000 [=============>................] - ETA: 1s - loss: 1.8181 - accuracy: 0.3249
19648/40000 [=============>................] - ETA: 1s - loss: 1.8075 - accuracy: 0.3288
20544/40000 [==============>...............] - ETA: 1s - loss: 1.7967 - accuracy: 0.3331
21376/40000 [===============>..............] - ETA: 1s - loss: 1.7871 - accuracy: 0.3367
22272/40000 [===============>..............] - ETA: 1s - loss: 1.7762 - accuracy: 0.3405
23168/40000 [================>.............] - ETA: 1s - loss: 1.7633 - accuracy: 0.3451
24064/40000 [=================>............] - ETA: 1s - loss: 1.7515 - accuracy: 0.3500
24896/40000 [=================>............] - ETA: 1s - loss: 1.7444 - accuracy: 0.3533
25728/40000 [==================>...........] - ETA: 0s - loss: 1.7360 - accuracy: 0.3565
26560/40000 [==================>...........] - ETA: 0s - loss: 1.7268 - accuracy: 0.3600
27456/40000 [===================>..........] - ETA: 0s - loss: 1.7171 - accuracy: 0.3637
28288/40000 [====================>.........] - ETA: 0s - loss: 1.7093 - accuracy: 0.3671
29120/40000 [====================>.........] - ETA: 0s - loss: 1.7022 - accuracy: 0.3701
29952/40000 [=====================>........] - ETA: 0s - loss: 1.6947 - accuracy: 0.3729
30784/40000 [======================>.......] - ETA: 0s - loss: 1.6890 - accuracy: 0.3752
31680/40000 [======================>.......] - ETA: 0s - loss: 1.6822 - accuracy: 0.3775
32576/40000 [=======================>......] - ETA: 0s - loss: 1.6765 - accuracy: 0.3797
33472/40000 [========================>.....] - ETA: 0s - loss: 1.6690 - accuracy: 0.3826
34304/40000 [========================>.....] - ETA: 0s - loss: 1.6621 - accuracy: 0.3854
35136/40000 [=========================>....] - ETA: 0s - loss: 1.6543 - accuracy: 0.3888
36032/40000 [==========================>...] - ETA: 0s - loss: 1.6494 - accuracy: 0.3911
36928/40000 [==========================>...] - ETA: 0s - loss: 1.6426 - accuracy: 0.3937
37760/40000 [===========================>..] - ETA: 0s - loss: 1.6359 - accuracy: 0.3962
38592/40000 [===========================>..] - ETA: 0s - loss: 1.6300 - accuracy: 0.3982
39424/40000 [============================>.] - ETA: 0s - loss: 1.6239 - accuracy: 0.4003
40000/40000 [==============================] - 3s 75us/step - loss: 1.6182 - accuracy: 0.4023 - val_loss: 1.3290 - val_accuracy: 0.5241
Score [1.3307083057403564, 0.5271000266075134]
test data shape (10000, 32, 32, 3)
Loss: 1.3307083057403564 / Accuracy: 0.5271000266075134
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3202 - accuracy: 0.0781
  640/40000 [..............................] - ETA: 11s - loss: 2.3031 - accuracy: 0.1125 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2920 - accuracy: 0.1211 
 1856/40000 [>.............................] - ETA: 5s - loss: 2.2617 - accuracy: 0.1352
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2179 - accuracy: 0.1567
 3136/40000 [=>............................] - ETA: 4s - loss: 2.1912 - accuracy: 0.1690
 3776/40000 [=>............................] - ETA: 4s - loss: 2.1600 - accuracy: 0.1814
 4480/40000 [==>...........................] - ETA: 3s - loss: 2.1332 - accuracy: 0.1879
 5248/40000 [==>...........................] - ETA: 3s - loss: 2.1274 - accuracy: 0.1909
 6016/40000 [===>..........................] - ETA: 3s - loss: 2.1047 - accuracy: 0.1961
 6848/40000 [====>.........................] - ETA: 3s - loss: 2.0840 - accuracy: 0.2058
 7680/40000 [====>.........................] - ETA: 2s - loss: 2.0631 - accuracy: 0.2139
 8512/40000 [=====>........................] - ETA: 2s - loss: 2.0425 - accuracy: 0.2215
 9344/40000 [======>.......................] - ETA: 2s - loss: 2.0202 - accuracy: 0.2301
10176/40000 [======>.......................] - ETA: 2s - loss: 1.9995 - accuracy: 0.2399
11072/40000 [=======>......................] - ETA: 2s - loss: 1.9846 - accuracy: 0.2432
11968/40000 [=======>......................] - ETA: 2s - loss: 1.9679 - accuracy: 0.2509
12800/40000 [========>.....................] - ETA: 2s - loss: 1.9514 - accuracy: 0.2573
13632/40000 [=========>....................] - ETA: 2s - loss: 1.9381 - accuracy: 0.2639
14464/40000 [=========>....................] - ETA: 1s - loss: 1.9209 - accuracy: 0.2713
15360/40000 [==========>...................] - ETA: 1s - loss: 1.9080 - accuracy: 0.2770
16256/40000 [===========>..................] - ETA: 1s - loss: 1.8908 - accuracy: 0.2847
17088/40000 [===========>..................] - ETA: 1s - loss: 1.8778 - accuracy: 0.2910
17920/40000 [============>.................] - ETA: 1s - loss: 1.8631 - accuracy: 0.2983
18752/40000 [=============>................] - ETA: 1s - loss: 1.8491 - accuracy: 0.3044
19648/40000 [=============>................] - ETA: 1s - loss: 1.8369 - accuracy: 0.3100
20544/40000 [==============>...............] - ETA: 1s - loss: 1.8223 - accuracy: 0.3151
21376/40000 [===============>..............] - ETA: 1s - loss: 1.8141 - accuracy: 0.3190
22208/40000 [===============>..............] - ETA: 1s - loss: 1.8065 - accuracy: 0.3222
23040/40000 [================>.............] - ETA: 1s - loss: 1.7976 - accuracy: 0.3253
23936/40000 [================>.............] - ETA: 1s - loss: 1.7856 - accuracy: 0.3309
24832/40000 [=================>............] - ETA: 1s - loss: 1.7741 - accuracy: 0.3362
25664/40000 [==================>...........] - ETA: 1s - loss: 1.7675 - accuracy: 0.3389
26496/40000 [==================>...........] - ETA: 0s - loss: 1.7579 - accuracy: 0.3422
27392/40000 [===================>..........] - ETA: 0s - loss: 1.7462 - accuracy: 0.3473
28288/40000 [====================>.........] - ETA: 0s - loss: 1.7373 - accuracy: 0.3503
29120/40000 [====================>.........] - ETA: 0s - loss: 1.7286 - accuracy: 0.3540
29952/40000 [=====================>........] - ETA: 0s - loss: 1.7186 - accuracy: 0.3577
30848/40000 [======================>.......] - ETA: 0s - loss: 1.7088 - accuracy: 0.3614
31744/40000 [======================>.......] - ETA: 0s - loss: 1.7009 - accuracy: 0.3650
32640/40000 [=======================>......] - ETA: 0s - loss: 1.6924 - accuracy: 0.3688
33536/40000 [========================>.....] - ETA: 0s - loss: 1.6840 - accuracy: 0.3722
34368/40000 [========================>.....] - ETA: 0s - loss: 1.6790 - accuracy: 0.3745
35200/40000 [=========================>....] - ETA: 0s - loss: 1.6731 - accuracy: 0.3770
36032/40000 [==========================>...] - ETA: 0s - loss: 1.6655 - accuracy: 0.3802
36928/40000 [==========================>...] - ETA: 0s - loss: 1.6581 - accuracy: 0.3832
37824/40000 [===========================>..] - ETA: 0s - loss: 1.6515 - accuracy: 0.3859
38656/40000 [===========================>..] - ETA: 0s - loss: 1.6454 - accuracy: 0.3882
39488/40000 [============================>.] - ETA: 0s - loss: 1.6386 - accuracy: 0.3907
40000/40000 [==============================] - 3s 75us/step - loss: 1.6348 - accuracy: 0.3923 - val_loss: 1.3634 - val_accuracy: 0.5066
Score [1.361172520828247, 0.510200023651123]
test data shape (10000, 32, 32, 3)
Loss: 1.361172520828247 / Accuracy: 0.510200023651123
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3020 - accuracy: 0.0781
  640/40000 [..............................] - ETA: 11s - loss: 2.2976 - accuracy: 0.1078 
 1216/40000 [..............................] - ETA: 7s - loss: 2.2826 - accuracy: 0.1316 
 1728/40000 [>.............................] - ETA: 6s - loss: 2.2693 - accuracy: 0.1343
 2304/40000 [>.............................] - ETA: 5s - loss: 2.2385 - accuracy: 0.1562
 3072/40000 [=>............................] - ETA: 4s - loss: 2.2028 - accuracy: 0.1686
 3840/40000 [=>............................] - ETA: 4s - loss: 2.1753 - accuracy: 0.1846
 4608/40000 [==>...........................] - ETA: 3s - loss: 2.1429 - accuracy: 0.1957
 5376/40000 [===>..........................] - ETA: 3s - loss: 2.1188 - accuracy: 0.2042
 6208/40000 [===>..........................] - ETA: 3s - loss: 2.0968 - accuracy: 0.2142
 7040/40000 [====>.........................] - ETA: 3s - loss: 2.0726 - accuracy: 0.2268
 7872/40000 [====>.........................] - ETA: 2s - loss: 2.0468 - accuracy: 0.2350
 8704/40000 [=====>........................] - ETA: 2s - loss: 2.0297 - accuracy: 0.2413
 9536/40000 [======>.......................] - ETA: 2s - loss: 2.0117 - accuracy: 0.2461
10368/40000 [======>.......................] - ETA: 2s - loss: 1.9935 - accuracy: 0.2532
11200/40000 [=======>......................] - ETA: 2s - loss: 1.9700 - accuracy: 0.2626
12096/40000 [========>.....................] - ETA: 2s - loss: 1.9521 - accuracy: 0.2704
12928/40000 [========>.....................] - ETA: 2s - loss: 1.9352 - accuracy: 0.2760
13760/40000 [=========>....................] - ETA: 2s - loss: 1.9236 - accuracy: 0.2809
14592/40000 [=========>....................] - ETA: 1s - loss: 1.9081 - accuracy: 0.2877
15424/40000 [==========>...................] - ETA: 1s - loss: 1.8950 - accuracy: 0.2933
16320/40000 [===========>..................] - ETA: 1s - loss: 1.8789 - accuracy: 0.2990
17152/40000 [===========>..................] - ETA: 1s - loss: 1.8656 - accuracy: 0.3046
17984/40000 [============>.................] - ETA: 1s - loss: 1.8539 - accuracy: 0.3086
18816/40000 [=============>................] - ETA: 1s - loss: 1.8424 - accuracy: 0.3132
19712/40000 [=============>................] - ETA: 1s - loss: 1.8291 - accuracy: 0.3195
20608/40000 [==============>...............] - ETA: 1s - loss: 1.8169 - accuracy: 0.3243
21440/40000 [===============>..............] - ETA: 1s - loss: 1.8063 - accuracy: 0.3282
22272/40000 [===============>..............] - ETA: 1s - loss: 1.7958 - accuracy: 0.3318
23104/40000 [================>.............] - ETA: 1s - loss: 1.7860 - accuracy: 0.3357
24000/40000 [=================>............] - ETA: 1s - loss: 1.7748 - accuracy: 0.3400
24832/40000 [=================>............] - ETA: 1s - loss: 1.7662 - accuracy: 0.3438
25664/40000 [==================>...........] - ETA: 1s - loss: 1.7555 - accuracy: 0.3481
26496/40000 [==================>...........] - ETA: 0s - loss: 1.7457 - accuracy: 0.3514
27328/40000 [===================>..........] - ETA: 0s - loss: 1.7337 - accuracy: 0.3563
28160/40000 [====================>.........] - ETA: 0s - loss: 1.7250 - accuracy: 0.3599
28992/40000 [====================>.........] - ETA: 0s - loss: 1.7191 - accuracy: 0.3627
29760/40000 [=====================>........] - ETA: 0s - loss: 1.7121 - accuracy: 0.3660
30656/40000 [=====================>........] - ETA: 0s - loss: 1.7044 - accuracy: 0.3688
31552/40000 [======================>.......] - ETA: 0s - loss: 1.6958 - accuracy: 0.3721
32384/40000 [=======================>......] - ETA: 0s - loss: 1.6916 - accuracy: 0.3741
33216/40000 [=======================>......] - ETA: 0s - loss: 1.6863 - accuracy: 0.3758
34048/40000 [========================>.....] - ETA: 0s - loss: 1.6794 - accuracy: 0.3786
34880/40000 [=========================>....] - ETA: 0s - loss: 1.6720 - accuracy: 0.3820
35776/40000 [=========================>....] - ETA: 0s - loss: 1.6652 - accuracy: 0.3846
36672/40000 [==========================>...] - ETA: 0s - loss: 1.6590 - accuracy: 0.3870
37504/40000 [===========================>..] - ETA: 0s - loss: 1.6531 - accuracy: 0.3892
38336/40000 [===========================>..] - ETA: 0s - loss: 1.6465 - accuracy: 0.3917
39168/40000 [============================>.] - ETA: 0s - loss: 1.6398 - accuracy: 0.3948
40000/40000 [==============================] - 3s 76us/step - loss: 1.6342 - accuracy: 0.3966 - val_loss: 1.3558 - val_accuracy: 0.5094
Score [1.3657971717834472, 0.5085999965667725]
test data shape (10000, 32, 32, 3)
Loss: 1.3657971717834472 / Accuracy: 0.5085999965667725
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:22 - loss: 2.3208 - accuracy: 0.0312
  704/40000 [..............................] - ETA: 10s - loss: 2.3046 - accuracy: 0.1122 
 1344/40000 [>.............................] - ETA: 6s - loss: 2.2864 - accuracy: 0.1280 
 1856/40000 [>.............................] - ETA: 5s - loss: 2.2571 - accuracy: 0.1466
 2432/40000 [>.............................] - ETA: 5s - loss: 2.2277 - accuracy: 0.1558
 3072/40000 [=>............................] - ETA: 4s - loss: 2.2001 - accuracy: 0.1644
 3904/40000 [=>............................] - ETA: 4s - loss: 2.1684 - accuracy: 0.1826
 4672/40000 [==>...........................] - ETA: 3s - loss: 2.1394 - accuracy: 0.2012
 5440/40000 [===>..........................] - ETA: 3s - loss: 2.1062 - accuracy: 0.2142
 6272/40000 [===>..........................] - ETA: 3s - loss: 2.0751 - accuracy: 0.2282
 7168/40000 [====>.........................] - ETA: 3s - loss: 2.0540 - accuracy: 0.2349
 8064/40000 [=====>........................] - ETA: 2s - loss: 2.0295 - accuracy: 0.2423
 8896/40000 [=====>........................] - ETA: 2s - loss: 2.0061 - accuracy: 0.2537
 9728/40000 [======>.......................] - ETA: 2s - loss: 1.9830 - accuracy: 0.2619
10624/40000 [======>.......................] - ETA: 2s - loss: 1.9620 - accuracy: 0.2703
11520/40000 [=======>......................] - ETA: 2s - loss: 1.9405 - accuracy: 0.2776
12416/40000 [========>.....................] - ETA: 2s - loss: 1.9221 - accuracy: 0.2844
13248/40000 [========>.....................] - ETA: 2s - loss: 1.9085 - accuracy: 0.2895
14080/40000 [=========>....................] - ETA: 1s - loss: 1.8970 - accuracy: 0.2942
14976/40000 [==========>...................] - ETA: 1s - loss: 1.8815 - accuracy: 0.2997
15872/40000 [==========>...................] - ETA: 1s - loss: 1.8652 - accuracy: 0.3052
16768/40000 [===========>..................] - ETA: 1s - loss: 1.8468 - accuracy: 0.3121
17664/40000 [============>.................] - ETA: 1s - loss: 1.8314 - accuracy: 0.3181
18560/40000 [============>.................] - ETA: 1s - loss: 1.8197 - accuracy: 0.3223
19456/40000 [=============>................] - ETA: 1s - loss: 1.8061 - accuracy: 0.3280
20352/40000 [==============>...............] - ETA: 1s - loss: 1.7940 - accuracy: 0.3319
21248/40000 [==============>...............] - ETA: 1s - loss: 1.7836 - accuracy: 0.3355
22080/40000 [===============>..............] - ETA: 1s - loss: 1.7755 - accuracy: 0.3401
22912/40000 [================>.............] - ETA: 1s - loss: 1.7652 - accuracy: 0.3443
23808/40000 [================>.............] - ETA: 1s - loss: 1.7532 - accuracy: 0.3486
24704/40000 [=================>............] - ETA: 1s - loss: 1.7448 - accuracy: 0.3517
25536/40000 [==================>...........] - ETA: 0s - loss: 1.7357 - accuracy: 0.3554
26368/40000 [==================>...........] - ETA: 0s - loss: 1.7283 - accuracy: 0.3581
27200/40000 [===================>..........] - ETA: 0s - loss: 1.7185 - accuracy: 0.3618
28096/40000 [====================>.........] - ETA: 0s - loss: 1.7072 - accuracy: 0.3663
28992/40000 [====================>.........] - ETA: 0s - loss: 1.6989 - accuracy: 0.3700
29888/40000 [=====================>........] - ETA: 0s - loss: 1.6916 - accuracy: 0.3734
30784/40000 [======================>.......] - ETA: 0s - loss: 1.6859 - accuracy: 0.3758
31680/40000 [======================>.......] - ETA: 0s - loss: 1.6790 - accuracy: 0.3787
32576/40000 [=======================>......] - ETA: 0s - loss: 1.6720 - accuracy: 0.3811
33472/40000 [========================>.....] - ETA: 0s - loss: 1.6645 - accuracy: 0.3841
34368/40000 [========================>.....] - ETA: 0s - loss: 1.6569 - accuracy: 0.3869
35264/40000 [=========================>....] - ETA: 0s - loss: 1.6489 - accuracy: 0.3900
36160/40000 [==========================>...] - ETA: 0s - loss: 1.6418 - accuracy: 0.3928
37056/40000 [==========================>...] - ETA: 0s - loss: 1.6347 - accuracy: 0.3955
37952/40000 [===========================>..] - ETA: 0s - loss: 1.6291 - accuracy: 0.3971
38848/40000 [============================>.] - ETA: 0s - loss: 1.6239 - accuracy: 0.3991
39744/40000 [============================>.] - ETA: 0s - loss: 1.6184 - accuracy: 0.4016
40000/40000 [==============================] - 3s 74us/step - loss: 1.6162 - accuracy: 0.4025 - val_loss: 1.2806 - val_accuracy: 0.5394
Score [1.2789009616851807, 0.5425999760627747]
test data shape (10000, 32, 32, 3)
Loss: 1.2789009616851807 / Accuracy: 0.5425999760627747
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.2937 - accuracy: 0.1094
  640/40000 [..............................] - ETA: 11s - loss: 2.3084 - accuracy: 0.1016 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2983 - accuracy: 0.1102 
 1856/40000 [>.............................] - ETA: 6s - loss: 2.2755 - accuracy: 0.1358
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2440 - accuracy: 0.1466
 3200/40000 [=>............................] - ETA: 4s - loss: 2.2106 - accuracy: 0.1562
 3904/40000 [=>............................] - ETA: 4s - loss: 2.1748 - accuracy: 0.1709
 4608/40000 [==>...........................] - ETA: 3s - loss: 2.1406 - accuracy: 0.1851
 5440/40000 [===>..........................] - ETA: 3s - loss: 2.1125 - accuracy: 0.1980
 6208/40000 [===>..........................] - ETA: 3s - loss: 2.0855 - accuracy: 0.2099
 7040/40000 [====>.........................] - ETA: 3s - loss: 2.0691 - accuracy: 0.2182
 7872/40000 [====>.........................] - ETA: 2s - loss: 2.0535 - accuracy: 0.2259
 8704/40000 [=====>........................] - ETA: 2s - loss: 2.0322 - accuracy: 0.2317
 9536/40000 [======>.......................] - ETA: 2s - loss: 2.0135 - accuracy: 0.2386
10432/40000 [======>.......................] - ETA: 2s - loss: 1.9902 - accuracy: 0.2493
11328/40000 [=======>......................] - ETA: 2s - loss: 1.9717 - accuracy: 0.2586
12224/40000 [========>.....................] - ETA: 2s - loss: 1.9507 - accuracy: 0.2662
13120/40000 [========>.....................] - ETA: 2s - loss: 1.9398 - accuracy: 0.2716
14016/40000 [=========>....................] - ETA: 1s - loss: 1.9259 - accuracy: 0.2777
14848/40000 [==========>...................] - ETA: 1s - loss: 1.9116 - accuracy: 0.2843
15744/40000 [==========>...................] - ETA: 1s - loss: 1.9000 - accuracy: 0.2894
16640/40000 [===========>..................] - ETA: 1s - loss: 1.8877 - accuracy: 0.2939
17472/40000 [============>.................] - ETA: 1s - loss: 1.8757 - accuracy: 0.2986
18304/40000 [============>.................] - ETA: 1s - loss: 1.8638 - accuracy: 0.3028
19136/40000 [=============>................] - ETA: 1s - loss: 1.8527 - accuracy: 0.3077
20032/40000 [==============>...............] - ETA: 1s - loss: 1.8407 - accuracy: 0.3117
20864/40000 [==============>...............] - ETA: 1s - loss: 1.8308 - accuracy: 0.3158
21760/40000 [===============>..............] - ETA: 1s - loss: 1.8201 - accuracy: 0.3203
22592/40000 [===============>..............] - ETA: 1s - loss: 1.8102 - accuracy: 0.3244
23488/40000 [================>.............] - ETA: 1s - loss: 1.8008 - accuracy: 0.3288
24384/40000 [=================>............] - ETA: 1s - loss: 1.7894 - accuracy: 0.3336
25216/40000 [=================>............] - ETA: 1s - loss: 1.7814 - accuracy: 0.3366
26048/40000 [==================>...........] - ETA: 0s - loss: 1.7738 - accuracy: 0.3398
26944/40000 [===================>..........] - ETA: 0s - loss: 1.7644 - accuracy: 0.3432
27840/40000 [===================>..........] - ETA: 0s - loss: 1.7559 - accuracy: 0.3464
28736/40000 [====================>.........] - ETA: 0s - loss: 1.7487 - accuracy: 0.3493
29568/40000 [=====================>........] - ETA: 0s - loss: 1.7399 - accuracy: 0.3533
30400/40000 [=====================>........] - ETA: 0s - loss: 1.7345 - accuracy: 0.3557
31232/40000 [======================>.......] - ETA: 0s - loss: 1.7266 - accuracy: 0.3588
32128/40000 [=======================>......] - ETA: 0s - loss: 1.7202 - accuracy: 0.3616
33024/40000 [=======================>......] - ETA: 0s - loss: 1.7119 - accuracy: 0.3649
33856/40000 [========================>.....] - ETA: 0s - loss: 1.7041 - accuracy: 0.3677
34688/40000 [=========================>....] - ETA: 0s - loss: 1.6960 - accuracy: 0.3706
35584/40000 [=========================>....] - ETA: 0s - loss: 1.6886 - accuracy: 0.3734
36480/40000 [==========================>...] - ETA: 0s - loss: 1.6806 - accuracy: 0.3763
37376/40000 [===========================>..] - ETA: 0s - loss: 1.6728 - accuracy: 0.3792
38208/40000 [===========================>..] - ETA: 0s - loss: 1.6677 - accuracy: 0.3813
39040/40000 [============================>.] - ETA: 0s - loss: 1.6631 - accuracy: 0.3833
39936/40000 [============================>.] - ETA: 0s - loss: 1.6573 - accuracy: 0.3858
40000/40000 [==============================] - 3s 74us/step - loss: 1.6568 - accuracy: 0.3860 - val_loss: 1.3591 - val_accuracy: 0.5085
Score [1.3746306512832642, 0.5120000243186951]
test data shape (10000, 32, 32, 3)
Loss: 1.3746306512832642 / Accuracy: 0.5120000243186951
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3178 - accuracy: 0.0781
  640/40000 [..............................] - ETA: 11s - loss: 2.3018 - accuracy: 0.1234 
 1280/40000 [..............................] - ETA: 7s - loss: 2.3004 - accuracy: 0.1180 
 1856/40000 [>.............................] - ETA: 5s - loss: 2.2907 - accuracy: 0.1336
 2432/40000 [>.............................] - ETA: 5s - loss: 2.2612 - accuracy: 0.1484
 3008/40000 [=>............................] - ETA: 4s - loss: 2.2394 - accuracy: 0.1579
 3648/40000 [=>............................] - ETA: 4s - loss: 2.2113 - accuracy: 0.1647
 4416/40000 [==>...........................] - ETA: 4s - loss: 2.1771 - accuracy: 0.1771
 5184/40000 [==>...........................] - ETA: 3s - loss: 2.1538 - accuracy: 0.1865
 5952/40000 [===>..........................] - ETA: 3s - loss: 2.1249 - accuracy: 0.1976
 6784/40000 [====>.........................] - ETA: 3s - loss: 2.0949 - accuracy: 0.2101
 7616/40000 [====>.........................] - ETA: 3s - loss: 2.0645 - accuracy: 0.2235
 8448/40000 [=====>........................] - ETA: 2s - loss: 2.0396 - accuracy: 0.2334
 9216/40000 [=====>........................] - ETA: 2s - loss: 2.0188 - accuracy: 0.2401
10112/40000 [======>.......................] - ETA: 2s - loss: 2.0017 - accuracy: 0.2472
10944/40000 [=======>......................] - ETA: 2s - loss: 1.9881 - accuracy: 0.2526
11776/40000 [=======>......................] - ETA: 2s - loss: 1.9703 - accuracy: 0.2602
12608/40000 [========>.....................] - ETA: 2s - loss: 1.9515 - accuracy: 0.2684
13440/40000 [=========>....................] - ETA: 2s - loss: 1.9347 - accuracy: 0.2751
14336/40000 [=========>....................] - ETA: 2s - loss: 1.9196 - accuracy: 0.2819
15168/40000 [==========>...................] - ETA: 1s - loss: 1.9034 - accuracy: 0.2884
16000/40000 [===========>..................] - ETA: 1s - loss: 1.8912 - accuracy: 0.2959
16832/40000 [===========>..................] - ETA: 1s - loss: 1.8765 - accuracy: 0.3023
17664/40000 [============>.................] - ETA: 1s - loss: 1.8633 - accuracy: 0.3066
18560/40000 [============>.................] - ETA: 1s - loss: 1.8487 - accuracy: 0.3119
19456/40000 [=============>................] - ETA: 1s - loss: 1.8389 - accuracy: 0.3152
20288/40000 [==============>...............] - ETA: 1s - loss: 1.8292 - accuracy: 0.3191
21056/40000 [==============>...............] - ETA: 1s - loss: 1.8181 - accuracy: 0.3231
21952/40000 [===============>..............] - ETA: 1s - loss: 1.8070 - accuracy: 0.3281
22848/40000 [================>.............] - ETA: 1s - loss: 1.7980 - accuracy: 0.3320
23744/40000 [================>.............] - ETA: 1s - loss: 1.7896 - accuracy: 0.3363
24576/40000 [=================>............] - ETA: 1s - loss: 1.7783 - accuracy: 0.3409
25408/40000 [==================>...........] - ETA: 1s - loss: 1.7689 - accuracy: 0.3448
26240/40000 [==================>...........] - ETA: 0s - loss: 1.7592 - accuracy: 0.3481
27136/40000 [===================>..........] - ETA: 0s - loss: 1.7504 - accuracy: 0.3522
28032/40000 [====================>.........] - ETA: 0s - loss: 1.7422 - accuracy: 0.3554
28864/40000 [====================>.........] - ETA: 0s - loss: 1.7315 - accuracy: 0.3593
29696/40000 [=====================>........] - ETA: 0s - loss: 1.7254 - accuracy: 0.3620
30592/40000 [=====================>........] - ETA: 0s - loss: 1.7167 - accuracy: 0.3652
31488/40000 [======================>.......] - ETA: 0s - loss: 1.7104 - accuracy: 0.3676
32384/40000 [=======================>......] - ETA: 0s - loss: 1.7027 - accuracy: 0.3706
33216/40000 [=======================>......] - ETA: 0s - loss: 1.6959 - accuracy: 0.3734
34048/40000 [========================>.....] - ETA: 0s - loss: 1.6898 - accuracy: 0.3761
34880/40000 [=========================>....] - ETA: 0s - loss: 1.6837 - accuracy: 0.3787
35776/40000 [=========================>....] - ETA: 0s - loss: 1.6773 - accuracy: 0.3808
36672/40000 [==========================>...] - ETA: 0s - loss: 1.6687 - accuracy: 0.3842
37504/40000 [===========================>..] - ETA: 0s - loss: 1.6631 - accuracy: 0.3863
38336/40000 [===========================>..] - ETA: 0s - loss: 1.6563 - accuracy: 0.3886
39232/40000 [============================>.] - ETA: 0s - loss: 1.6487 - accuracy: 0.3918
40000/40000 [==============================] - 3s 76us/step - loss: 1.6447 - accuracy: 0.3934 - val_loss: 1.3818 - val_accuracy: 0.5075
Score [1.3835442464828491, 0.5044999718666077]
test data shape (10000, 32, 32, 3)
Loss: 1.3835442464828491 / Accuracy: 0.5044999718666077
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3030 - accuracy: 0.0781
  640/40000 [..............................] - ETA: 11s - loss: 2.3044 - accuracy: 0.1016 
 1216/40000 [..............................] - ETA: 7s - loss: 2.2906 - accuracy: 0.1250 
 1792/40000 [>.............................] - ETA: 6s - loss: 2.2740 - accuracy: 0.1278
 2368/40000 [>.............................] - ETA: 5s - loss: 2.2371 - accuracy: 0.1402
 3072/40000 [=>............................] - ETA: 4s - loss: 2.2117 - accuracy: 0.1605
 3712/40000 [=>............................] - ETA: 4s - loss: 2.1903 - accuracy: 0.1657
 4416/40000 [==>...........................] - ETA: 3s - loss: 2.1692 - accuracy: 0.1739
 5248/40000 [==>...........................] - ETA: 3s - loss: 2.1394 - accuracy: 0.1837
 6080/40000 [===>..........................] - ETA: 3s - loss: 2.1134 - accuracy: 0.1954
 6912/40000 [====>.........................] - ETA: 3s - loss: 2.0880 - accuracy: 0.2056
 7744/40000 [====>.........................] - ETA: 2s - loss: 2.0607 - accuracy: 0.2189
 8576/40000 [=====>........................] - ETA: 2s - loss: 2.0340 - accuracy: 0.2281
 9408/40000 [======>.......................] - ETA: 2s - loss: 2.0140 - accuracy: 0.2363
10304/40000 [======>.......................] - ETA: 2s - loss: 1.9899 - accuracy: 0.2456
11136/40000 [=======>......................] - ETA: 2s - loss: 1.9731 - accuracy: 0.2535
12032/40000 [========>.....................] - ETA: 2s - loss: 1.9539 - accuracy: 0.2625
12864/40000 [========>.....................] - ETA: 2s - loss: 1.9383 - accuracy: 0.2690
13696/40000 [=========>....................] - ETA: 2s - loss: 1.9222 - accuracy: 0.2746
14592/40000 [=========>....................] - ETA: 1s - loss: 1.9064 - accuracy: 0.2820
15488/40000 [==========>...................] - ETA: 1s - loss: 1.8893 - accuracy: 0.2885
16384/40000 [===========>..................] - ETA: 1s - loss: 1.8708 - accuracy: 0.2954
17216/40000 [===========>..................] - ETA: 1s - loss: 1.8576 - accuracy: 0.3007
18048/40000 [============>.................] - ETA: 1s - loss: 1.8471 - accuracy: 0.3053
18944/40000 [=============>................] - ETA: 1s - loss: 1.8346 - accuracy: 0.3108
19840/40000 [=============>................] - ETA: 1s - loss: 1.8235 - accuracy: 0.3147
20736/40000 [==============>...............] - ETA: 1s - loss: 1.8113 - accuracy: 0.3202
21568/40000 [===============>..............] - ETA: 1s - loss: 1.7990 - accuracy: 0.3252
22400/40000 [===============>..............] - ETA: 1s - loss: 1.7894 - accuracy: 0.3290
23232/40000 [================>.............] - ETA: 1s - loss: 1.7851 - accuracy: 0.3305
24128/40000 [=================>............] - ETA: 1s - loss: 1.7758 - accuracy: 0.3343
24960/40000 [=================>............] - ETA: 1s - loss: 1.7667 - accuracy: 0.3388
25856/40000 [==================>...........] - ETA: 0s - loss: 1.7581 - accuracy: 0.3431
26688/40000 [===================>..........] - ETA: 0s - loss: 1.7493 - accuracy: 0.3468
27584/40000 [===================>..........] - ETA: 0s - loss: 1.7407 - accuracy: 0.3501
28480/40000 [====================>.........] - ETA: 0s - loss: 1.7309 - accuracy: 0.3541
29312/40000 [====================>.........] - ETA: 0s - loss: 1.7218 - accuracy: 0.3582
30208/40000 [=====================>........] - ETA: 0s - loss: 1.7126 - accuracy: 0.3617
31104/40000 [======================>.......] - ETA: 0s - loss: 1.7047 - accuracy: 0.3643
32000/40000 [=======================>......] - ETA: 0s - loss: 1.6973 - accuracy: 0.3669
32896/40000 [=======================>......] - ETA: 0s - loss: 1.6908 - accuracy: 0.3698
33792/40000 [========================>.....] - ETA: 0s - loss: 1.6853 - accuracy: 0.3722
34624/40000 [========================>.....] - ETA: 0s - loss: 1.6789 - accuracy: 0.3745
35520/40000 [=========================>....] - ETA: 0s - loss: 1.6718 - accuracy: 0.3773
36480/40000 [==========================>...] - ETA: 0s - loss: 1.6658 - accuracy: 0.3798
37376/40000 [===========================>..] - ETA: 0s - loss: 1.6592 - accuracy: 0.3829
38208/40000 [===========================>..] - ETA: 0s - loss: 1.6532 - accuracy: 0.3852
39040/40000 [============================>.] - ETA: 0s - loss: 1.6459 - accuracy: 0.3881
39936/40000 [============================>.] - ETA: 0s - loss: 1.6389 - accuracy: 0.3911
40000/40000 [==============================] - 3s 74us/step - loss: 1.6383 - accuracy: 0.3913 - val_loss: 1.3648 - val_accuracy: 0.4977
Score [1.3710500230789184, 0.5019000172615051]
test data shape (10000, 32, 32, 3)
Loss: 1.3710500230789184 / Accuracy: 0.5019000172615051
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.2989 - accuracy: 0.1406
  704/40000 [..............................] - ETA: 10s - loss: 2.3030 - accuracy: 0.1264 
 1344/40000 [>.............................] - ETA: 6s - loss: 2.3006 - accuracy: 0.1332 
 1920/40000 [>.............................] - ETA: 5s - loss: 2.2924 - accuracy: 0.1255
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2788 - accuracy: 0.1310
 3136/40000 [=>............................] - ETA: 4s - loss: 2.2551 - accuracy: 0.1371
 3968/40000 [=>............................] - ETA: 4s - loss: 2.2012 - accuracy: 0.1583
 4736/40000 [==>...........................] - ETA: 3s - loss: 2.1632 - accuracy: 0.1717
 5504/40000 [===>..........................] - ETA: 3s - loss: 2.1298 - accuracy: 0.1830
 6336/40000 [===>..........................] - ETA: 3s - loss: 2.0974 - accuracy: 0.1927
 7232/40000 [====>.........................] - ETA: 2s - loss: 2.0704 - accuracy: 0.2034
 8064/40000 [=====>........................] - ETA: 2s - loss: 2.0457 - accuracy: 0.2148
 8960/40000 [=====>........................] - ETA: 2s - loss: 2.0257 - accuracy: 0.2262
 9792/40000 [======>.......................] - ETA: 2s - loss: 2.0115 - accuracy: 0.2340
10688/40000 [=======>......................] - ETA: 2s - loss: 1.9913 - accuracy: 0.2443
11520/40000 [=======>......................] - ETA: 2s - loss: 1.9714 - accuracy: 0.2536
12416/40000 [========>.....................] - ETA: 2s - loss: 1.9515 - accuracy: 0.2630
13248/40000 [========>.....................] - ETA: 2s - loss: 1.9341 - accuracy: 0.2700
14144/40000 [=========>....................] - ETA: 1s - loss: 1.9188 - accuracy: 0.2753
15040/40000 [==========>...................] - ETA: 1s - loss: 1.9028 - accuracy: 0.2819
15872/40000 [==========>...................] - ETA: 1s - loss: 1.8884 - accuracy: 0.2879
16704/40000 [===========>..................] - ETA: 1s - loss: 1.8747 - accuracy: 0.2933
17536/40000 [============>.................] - ETA: 1s - loss: 1.8647 - accuracy: 0.2966
18432/40000 [============>.................] - ETA: 1s - loss: 1.8519 - accuracy: 0.3020
19328/40000 [=============>................] - ETA: 1s - loss: 1.8386 - accuracy: 0.3072
20224/40000 [==============>...............] - ETA: 1s - loss: 1.8257 - accuracy: 0.3117
21120/40000 [==============>...............] - ETA: 1s - loss: 1.8129 - accuracy: 0.3159
21952/40000 [===============>..............] - ETA: 1s - loss: 1.8024 - accuracy: 0.3200
22848/40000 [================>.............] - ETA: 1s - loss: 1.7927 - accuracy: 0.3237
23744/40000 [================>.............] - ETA: 1s - loss: 1.7825 - accuracy: 0.3283
24576/40000 [=================>............] - ETA: 1s - loss: 1.7719 - accuracy: 0.3329
25408/40000 [==================>...........] - ETA: 0s - loss: 1.7623 - accuracy: 0.3369
26240/40000 [==================>...........] - ETA: 0s - loss: 1.7530 - accuracy: 0.3405
27136/40000 [===================>..........] - ETA: 0s - loss: 1.7436 - accuracy: 0.3439
28032/40000 [====================>.........] - ETA: 0s - loss: 1.7355 - accuracy: 0.3477
28928/40000 [====================>.........] - ETA: 0s - loss: 1.7281 - accuracy: 0.3511
29760/40000 [=====================>........] - ETA: 0s - loss: 1.7210 - accuracy: 0.3542
30656/40000 [=====================>........] - ETA: 0s - loss: 1.7116 - accuracy: 0.3586
31552/40000 [======================>.......] - ETA: 0s - loss: 1.7026 - accuracy: 0.3625
32448/40000 [=======================>......] - ETA: 0s - loss: 1.6943 - accuracy: 0.3659
33280/40000 [=======================>......] - ETA: 0s - loss: 1.6873 - accuracy: 0.3691
34112/40000 [========================>.....] - ETA: 0s - loss: 1.6809 - accuracy: 0.3719
35008/40000 [=========================>....] - ETA: 0s - loss: 1.6736 - accuracy: 0.3746
35904/40000 [=========================>....] - ETA: 0s - loss: 1.6677 - accuracy: 0.3767
36800/40000 [==========================>...] - ETA: 0s - loss: 1.6593 - accuracy: 0.3801
37696/40000 [===========================>..] - ETA: 0s - loss: 1.6532 - accuracy: 0.3826
38528/40000 [===========================>..] - ETA: 0s - loss: 1.6483 - accuracy: 0.3846
39360/40000 [============================>.] - ETA: 0s - loss: 1.6435 - accuracy: 0.3862
40000/40000 [==============================] - 3s 74us/step - loss: 1.6390 - accuracy: 0.3883 - val_loss: 1.3211 - val_accuracy: 0.5173
Score [1.3225817504882813, 0.5192999839782715]
test data shape (10000, 32, 32, 3)
Loss: 1.3225817504882813 / Accuracy: 0.5192999839782715
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:22 - loss: 2.3135 - accuracy: 0.0781
  704/40000 [..............................] - ETA: 10s - loss: 2.3023 - accuracy: 0.0767 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2850 - accuracy: 0.1109 
 1856/40000 [>.............................] - ETA: 6s - loss: 2.2426 - accuracy: 0.1369
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2087 - accuracy: 0.1538
 3200/40000 [=>............................] - ETA: 4s - loss: 2.1781 - accuracy: 0.1675
 3904/40000 [=>............................] - ETA: 4s - loss: 2.1497 - accuracy: 0.1788
 4544/40000 [==>...........................] - ETA: 3s - loss: 2.1188 - accuracy: 0.1901
 5376/40000 [===>..........................] - ETA: 3s - loss: 2.0794 - accuracy: 0.2083
 6144/40000 [===>..........................] - ETA: 3s - loss: 2.0579 - accuracy: 0.2171
 6976/40000 [====>.........................] - ETA: 3s - loss: 2.0302 - accuracy: 0.2275
 7808/40000 [====>.........................] - ETA: 2s - loss: 2.0051 - accuracy: 0.2381
 8640/40000 [=====>........................] - ETA: 2s - loss: 1.9846 - accuracy: 0.2449
 9472/40000 [======>.......................] - ETA: 2s - loss: 1.9652 - accuracy: 0.2530
10304/40000 [======>.......................] - ETA: 2s - loss: 1.9488 - accuracy: 0.2614
11200/40000 [=======>......................] - ETA: 2s - loss: 1.9257 - accuracy: 0.2710
12096/40000 [========>.....................] - ETA: 2s - loss: 1.9091 - accuracy: 0.2776
12928/40000 [========>.....................] - ETA: 2s - loss: 1.8914 - accuracy: 0.2850
13760/40000 [=========>....................] - ETA: 2s - loss: 1.8759 - accuracy: 0.2910
14592/40000 [=========>....................] - ETA: 1s - loss: 1.8597 - accuracy: 0.2981
15488/40000 [==========>...................] - ETA: 1s - loss: 1.8444 - accuracy: 0.3044
16384/40000 [===========>..................] - ETA: 1s - loss: 1.8286 - accuracy: 0.3112
17216/40000 [===========>..................] - ETA: 1s - loss: 1.8164 - accuracy: 0.3166
18048/40000 [============>.................] - ETA: 1s - loss: 1.8025 - accuracy: 0.3232
18944/40000 [=============>................] - ETA: 1s - loss: 1.7911 - accuracy: 0.3289
19840/40000 [=============>................] - ETA: 1s - loss: 1.7780 - accuracy: 0.3349
20736/40000 [==============>...............] - ETA: 1s - loss: 1.7661 - accuracy: 0.3397
21568/40000 [===============>..............] - ETA: 1s - loss: 1.7576 - accuracy: 0.3432
22400/40000 [===============>..............] - ETA: 1s - loss: 1.7487 - accuracy: 0.3462
23232/40000 [================>.............] - ETA: 1s - loss: 1.7394 - accuracy: 0.3502
24128/40000 [=================>............] - ETA: 1s - loss: 1.7316 - accuracy: 0.3538
25024/40000 [=================>............] - ETA: 1s - loss: 1.7205 - accuracy: 0.3580
25856/40000 [==================>...........] - ETA: 0s - loss: 1.7115 - accuracy: 0.3615
26688/40000 [===================>..........] - ETA: 0s - loss: 1.7030 - accuracy: 0.3650
27520/40000 [===================>..........] - ETA: 0s - loss: 1.6932 - accuracy: 0.3690
28416/40000 [====================>.........] - ETA: 0s - loss: 1.6834 - accuracy: 0.3732
29312/40000 [====================>.........] - ETA: 0s - loss: 1.6746 - accuracy: 0.3763
30144/40000 [=====================>........] - ETA: 0s - loss: 1.6676 - accuracy: 0.3793
30976/40000 [======================>.......] - ETA: 0s - loss: 1.6603 - accuracy: 0.3818
31808/40000 [======================>.......] - ETA: 0s - loss: 1.6531 - accuracy: 0.3851
32704/40000 [=======================>......] - ETA: 0s - loss: 1.6456 - accuracy: 0.3880
33600/40000 [========================>.....] - ETA: 0s - loss: 1.6407 - accuracy: 0.3906
34496/40000 [========================>.....] - ETA: 0s - loss: 1.6346 - accuracy: 0.3929
35328/40000 [=========================>....] - ETA: 0s - loss: 1.6282 - accuracy: 0.3962
36160/40000 [==========================>...] - ETA: 0s - loss: 1.6213 - accuracy: 0.3993
37056/40000 [==========================>...] - ETA: 0s - loss: 1.6133 - accuracy: 0.4026
37952/40000 [===========================>..] - ETA: 0s - loss: 1.6058 - accuracy: 0.4059
38784/40000 [============================>.] - ETA: 0s - loss: 1.5998 - accuracy: 0.4083
39616/40000 [============================>.] - ETA: 0s - loss: 1.5935 - accuracy: 0.4113
40000/40000 [==============================] - 3s 75us/step - loss: 1.5911 - accuracy: 0.4122 - val_loss: 1.2773 - val_accuracy: 0.5387
Score [1.2784921403884888, 0.5351999998092651]
test data shape (10000, 32, 32, 3)
Loss: 1.2784921403884888 / Accuracy: 0.5351999998092651
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.2894 - accuracy: 0.1406
  704/40000 [..............................] - ETA: 10s - loss: 2.3055 - accuracy: 0.1165 
 1344/40000 [>.............................] - ETA: 6s - loss: 2.2972 - accuracy: 0.1176 
 1920/40000 [>.............................] - ETA: 5s - loss: 2.2785 - accuracy: 0.1339
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2442 - accuracy: 0.1486
 3136/40000 [=>............................] - ETA: 4s - loss: 2.2270 - accuracy: 0.1582
 3968/40000 [=>............................] - ETA: 4s - loss: 2.1992 - accuracy: 0.1668
 4736/40000 [==>...........................] - ETA: 3s - loss: 2.1698 - accuracy: 0.1776
 5504/40000 [===>..........................] - ETA: 3s - loss: 2.1448 - accuracy: 0.1890
 6336/40000 [===>..........................] - ETA: 3s - loss: 2.1218 - accuracy: 0.1984
 7232/40000 [====>.........................] - ETA: 2s - loss: 2.0926 - accuracy: 0.2088
 8128/40000 [=====>........................] - ETA: 2s - loss: 2.0663 - accuracy: 0.2181
 8960/40000 [=====>........................] - ETA: 2s - loss: 2.0411 - accuracy: 0.2252
 9856/40000 [======>.......................] - ETA: 2s - loss: 2.0202 - accuracy: 0.2331
10752/40000 [=======>......................] - ETA: 2s - loss: 1.9997 - accuracy: 0.2426
11648/40000 [=======>......................] - ETA: 2s - loss: 1.9824 - accuracy: 0.2504
12480/40000 [========>.....................] - ETA: 2s - loss: 1.9686 - accuracy: 0.2579
13312/40000 [========>.....................] - ETA: 2s - loss: 1.9521 - accuracy: 0.2634
14144/40000 [=========>....................] - ETA: 1s - loss: 1.9346 - accuracy: 0.2706
15040/40000 [==========>...................] - ETA: 1s - loss: 1.9163 - accuracy: 0.2777
15936/40000 [==========>...................] - ETA: 1s - loss: 1.8990 - accuracy: 0.2853
16768/40000 [===========>..................] - ETA: 1s - loss: 1.8811 - accuracy: 0.2923
17600/40000 [============>.................] - ETA: 1s - loss: 1.8690 - accuracy: 0.2971
18432/40000 [============>.................] - ETA: 1s - loss: 1.8566 - accuracy: 0.3024
19328/40000 [=============>................] - ETA: 1s - loss: 1.8448 - accuracy: 0.3077
20224/40000 [==============>...............] - ETA: 1s - loss: 1.8312 - accuracy: 0.3137
21056/40000 [==============>...............] - ETA: 1s - loss: 1.8211 - accuracy: 0.3177
21888/40000 [===============>..............] - ETA: 1s - loss: 1.8098 - accuracy: 0.3219
22720/40000 [================>.............] - ETA: 1s - loss: 1.8039 - accuracy: 0.3245
23616/40000 [================>.............] - ETA: 1s - loss: 1.7919 - accuracy: 0.3293
24512/40000 [=================>............] - ETA: 1s - loss: 1.7781 - accuracy: 0.3341
25344/40000 [==================>...........] - ETA: 1s - loss: 1.7679 - accuracy: 0.3377
26176/40000 [==================>...........] - ETA: 0s - loss: 1.7590 - accuracy: 0.3410
27072/40000 [===================>..........] - ETA: 0s - loss: 1.7477 - accuracy: 0.3452
27968/40000 [===================>..........] - ETA: 0s - loss: 1.7367 - accuracy: 0.3496
28800/40000 [====================>.........] - ETA: 0s - loss: 1.7293 - accuracy: 0.3528
29632/40000 [=====================>........] - ETA: 0s - loss: 1.7200 - accuracy: 0.3565
30400/40000 [=====================>........] - ETA: 0s - loss: 1.7136 - accuracy: 0.3593
31296/40000 [======================>.......] - ETA: 0s - loss: 1.7060 - accuracy: 0.3627
32192/40000 [=======================>......] - ETA: 0s - loss: 1.6987 - accuracy: 0.3660
33024/40000 [=======================>......] - ETA: 0s - loss: 1.6925 - accuracy: 0.3685
33856/40000 [========================>.....] - ETA: 0s - loss: 1.6850 - accuracy: 0.3709
34688/40000 [=========================>....] - ETA: 0s - loss: 1.6778 - accuracy: 0.3738
35520/40000 [=========================>....] - ETA: 0s - loss: 1.6701 - accuracy: 0.3769
36416/40000 [==========================>...] - ETA: 0s - loss: 1.6644 - accuracy: 0.3793
37248/40000 [==========================>...] - ETA: 0s - loss: 1.6575 - accuracy: 0.3819
38016/40000 [===========================>..] - ETA: 0s - loss: 1.6507 - accuracy: 0.3849
38912/40000 [============================>.] - ETA: 0s - loss: 1.6437 - accuracy: 0.3879
39808/40000 [============================>.] - ETA: 0s - loss: 1.6368 - accuracy: 0.3904
40000/40000 [==============================] - 3s 75us/step - loss: 1.6355 - accuracy: 0.3910 - val_loss: 1.3536 - val_accuracy: 0.5094
Score [1.350492569732666, 0.506600022315979]
test data shape (10000, 32, 32, 3)
Loss: 1.350492569732666 / Accuracy: 0.506600022315979
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:21 - loss: 2.3093 - accuracy: 0.0625
  640/40000 [..............................] - ETA: 11s - loss: 2.3049 - accuracy: 0.1016 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2959 - accuracy: 0.1148 
 1856/40000 [>.............................] - ETA: 6s - loss: 2.2831 - accuracy: 0.1239
 2496/40000 [>.............................] - ETA: 5s - loss: 2.2480 - accuracy: 0.1454
 3200/40000 [=>............................] - ETA: 4s - loss: 2.2170 - accuracy: 0.1572
 3904/40000 [=>............................] - ETA: 4s - loss: 2.1902 - accuracy: 0.1711
 4608/40000 [==>...........................] - ETA: 3s - loss: 2.1566 - accuracy: 0.1816
 5376/40000 [===>..........................] - ETA: 3s - loss: 2.1202 - accuracy: 0.1972
 6208/40000 [===>..........................] - ETA: 3s - loss: 2.0951 - accuracy: 0.2083
 7040/40000 [====>.........................] - ETA: 3s - loss: 2.0701 - accuracy: 0.2192
 7808/40000 [====>.........................] - ETA: 2s - loss: 2.0448 - accuracy: 0.2310
 8704/40000 [=====>........................] - ETA: 2s - loss: 2.0144 - accuracy: 0.2421
 9600/40000 [======>.......................] - ETA: 2s - loss: 1.9909 - accuracy: 0.2530
10496/40000 [======>.......................] - ETA: 2s - loss: 1.9683 - accuracy: 0.2626
11392/40000 [=======>......................] - ETA: 2s - loss: 1.9483 - accuracy: 0.2693
12224/40000 [========>.....................] - ETA: 2s - loss: 1.9291 - accuracy: 0.2775
13056/40000 [========>.....................] - ETA: 2s - loss: 1.9116 - accuracy: 0.2854
13952/40000 [=========>....................] - ETA: 2s - loss: 1.8925 - accuracy: 0.2936
14848/40000 [==========>...................] - ETA: 1s - loss: 1.8777 - accuracy: 0.3003
15744/40000 [==========>...................] - ETA: 1s - loss: 1.8641 - accuracy: 0.3055
16576/40000 [===========>..................] - ETA: 1s - loss: 1.8516 - accuracy: 0.3104
17408/40000 [============>.................] - ETA: 1s - loss: 1.8425 - accuracy: 0.3147
18304/40000 [============>.................] - ETA: 1s - loss: 1.8321 - accuracy: 0.3189
19200/40000 [=============>................] - ETA: 1s - loss: 1.8226 - accuracy: 0.3227
20032/40000 [==============>...............] - ETA: 1s - loss: 1.8095 - accuracy: 0.3270
20928/40000 [==============>...............] - ETA: 1s - loss: 1.7962 - accuracy: 0.3316
21760/40000 [===============>..............] - ETA: 1s - loss: 1.7870 - accuracy: 0.3362
22656/40000 [===============>..............] - ETA: 1s - loss: 1.7806 - accuracy: 0.3389
23552/40000 [================>.............] - ETA: 1s - loss: 1.7749 - accuracy: 0.3413
24384/40000 [=================>............] - ETA: 1s - loss: 1.7639 - accuracy: 0.3456
25216/40000 [=================>............] - ETA: 1s - loss: 1.7559 - accuracy: 0.3485
26048/40000 [==================>...........] - ETA: 0s - loss: 1.7473 - accuracy: 0.3522
26944/40000 [===================>..........] - ETA: 0s - loss: 1.7366 - accuracy: 0.3566
27840/40000 [===================>..........] - ETA: 0s - loss: 1.7285 - accuracy: 0.3602
28672/40000 [====================>.........] - ETA: 0s - loss: 1.7197 - accuracy: 0.3639
29568/40000 [=====================>........] - ETA: 0s - loss: 1.7124 - accuracy: 0.3667
30400/40000 [=====================>........] - ETA: 0s - loss: 1.7052 - accuracy: 0.3694
31296/40000 [======================>.......] - ETA: 0s - loss: 1.6961 - accuracy: 0.3726
32192/40000 [=======================>......] - ETA: 0s - loss: 1.6887 - accuracy: 0.3755
33024/40000 [=======================>......] - ETA: 0s - loss: 1.6818 - accuracy: 0.3782
33856/40000 [========================>.....] - ETA: 0s - loss: 1.6758 - accuracy: 0.3807
34752/40000 [=========================>....] - ETA: 0s - loss: 1.6690 - accuracy: 0.3835
35648/40000 [=========================>....] - ETA: 0s - loss: 1.6617 - accuracy: 0.3868
36480/40000 [==========================>...] - ETA: 0s - loss: 1.6552 - accuracy: 0.3894
37312/40000 [==========================>...] - ETA: 0s - loss: 1.6502 - accuracy: 0.3912
38144/40000 [===========================>..] - ETA: 0s - loss: 1.6438 - accuracy: 0.3936
39040/40000 [============================>.] - ETA: 0s - loss: 1.6383 - accuracy: 0.3958
39936/40000 [============================>.] - ETA: 0s - loss: 1.6305 - accuracy: 0.3987
40000/40000 [==============================] - 3s 75us/step - loss: 1.6301 - accuracy: 0.3988 - val_loss: 1.3117 - val_accuracy: 0.5256
Score [1.3162316442489623, 0.5160999894142151]
test data shape (10000, 32, 32, 3)
Loss: 1.3162316442489623 / Accuracy: 0.5160999894142151
Train on 40000 samples, validate on 10000 samples
Umlaut results:
[<Critical: Missing Softmax layer before loss>, <Warning: Last model layer has nonlinear activation>]
Epoch 1/1

   64/40000 [..............................] - ETA: 1:22 - loss: 2.2951 - accuracy: 0.1406
  704/40000 [..............................] - ETA: 10s - loss: 2.2996 - accuracy: 0.1037 
 1280/40000 [..............................] - ETA: 7s - loss: 2.2889 - accuracy: 0.1203 
 1792/40000 [>.............................] - ETA: 6s - loss: 2.2577 - accuracy: 0.1518
 2368/40000 [>.............................] - ETA: 5s - loss: 2.2173 - accuracy: 0.1605
 3136/40000 [=>............................] - ETA: 4s - loss: 2.1728 - accuracy: 0.1814
 3904/40000 [=>............................] - ETA: 4s - loss: 2.1418 - accuracy: 0.1929
 4608/40000 [==>...........................] - ETA: 3s - loss: 2.1060 - accuracy: 0.2088
 5376/40000 [===>..........................] - ETA: 3s - loss: 2.0747 - accuracy: 0.2204
 6208/40000 [===>..........................] - ETA: 3s - loss: 2.0622 - accuracy: 0.2286
 7104/40000 [====>.........................] - ETA: 3s - loss: 2.0372 - accuracy: 0.2387
 8000/40000 [=====>........................] - ETA: 2s - loss: 2.0147 - accuracy: 0.2488
 8832/40000 [=====>........................] - ETA: 2s - loss: 1.9958 - accuracy: 0.2546
 9664/40000 [======>.......................] - ETA: 2s - loss: 1.9789 - accuracy: 0.2615
10560/40000 [======>.......................] - ETA: 2s - loss: 1.9570 - accuracy: 0.2719
11456/40000 [=======>......................] - ETA: 2s - loss: 1.9389 - accuracy: 0.2773
12352/40000 [========>.....................] - ETA: 2s - loss: 1.9246 - accuracy: 0.2830
13248/40000 [========>.....................] - ETA: 2s - loss: 1.9142 - accuracy: 0.2869
14080/40000 [=========>....................] - ETA: 1s - loss: 1.9029 - accuracy: 0.2914
14912/40000 [==========>...................] - ETA: 1s - loss: 1.8859 - accuracy: 0.2970
15808/40000 [==========>...................] - ETA: 1s - loss: 1.8706 - accuracy: 0.3023
16704/40000 [===========>..................] - ETA: 1s - loss: 1.8544 - accuracy: 0.3092
17536/40000 [============>.................] - ETA: 1s - loss: 1.8426 - accuracy: 0.3142
18368/40000 [============>.................] - ETA: 1s - loss: 1.8338 - accuracy: 0.3188
19200/40000 [=============>................] - ETA: 1s - loss: 1.8237 - accuracy: 0.3223
20096/40000 [==============>...............] - ETA: 1s - loss: 1.8122 - accuracy: 0.3271
20992/40000 [==============>...............] - ETA: 1s - loss: 1.8010 - accuracy: 0.3317
21888/40000 [===============>..............] - ETA: 1s - loss: 1.7874 - accuracy: 0.3365
22720/40000 [================>.............] - ETA: 1s - loss: 1.7787 - accuracy: 0.3409
23616/40000 [================>.............] - ETA: 1s - loss: 1.7683 - accuracy: 0.3449
24448/40000 [=================>............] - ETA: 1s - loss: 1.7584 - accuracy: 0.3490
25344/40000 [==================>...........] - ETA: 1s - loss: 1.7494 - accuracy: 0.3526
26176/40000 [==================>...........] - ETA: 0s - loss: 1.7403 - accuracy: 0.3566
27008/40000 [===================>..........] - ETA: 0s - loss: 1.7317 - accuracy: 0.3595
27904/40000 [===================>..........] - ETA: 0s - loss: 1.7236 - accuracy: 0.3623
28800/40000 [====================>.........] - ETA: 0s - loss: 1.7151 - accuracy: 0.3655
29696/40000 [=====================>........] - ETA: 0s - loss: 1.7059 - accuracy: 0.3687
30592/40000 [=====================>........] - ETA: 0s - loss: 1.6990 - accuracy: 0.3717
31488/40000 [======================>.......] - ETA: 0s - loss: 1.6918 - accuracy: 0.3743
32320/40000 [=======================>......] - ETA: 0s - loss: 1.6847 - accuracy: 0.3772
33216/40000 [=======================>......] - ETA: 0s - loss: 1.6782 - accuracy: 0.3798
34112/40000 [========================>.....] - ETA: 0s - loss: 1.6715 - accuracy: 0.3822
35008/40000 [=========================>....] - ETA: 0s - loss: 1.6642 - accuracy: 0.3851
35840/40000 [=========================>....] - ETA: 0s - loss: 1.6583 - accuracy: 0.3874
36736/40000 [==========================>...] - ETA: 0s - loss: 1.6503 - accuracy: 0.3905
37632/40000 [===========================>..] - ETA: 0s - loss: 1.6437 - accuracy: 0.3932
38528/40000 [===========================>..] - ETA: 0s - loss: 1.6345 - accuracy: 0.3968
39360/40000 [============================>.] - ETA: 0s - loss: 1.6272 - accuracy: 0.3991
40000/40000 [==============================] - 3s 74us/step - loss: 1.6225 - accuracy: 0.4009 - val_loss: 1.3258 - val_accuracy: 0.5170
Score [1.3287814924240113, 0.5188999772071838]
test data shape (10000, 32, 32, 3)
Loss: 1.3287814924240113 / Accuracy: 0.5188999772071838

Process finished with exit code 0
